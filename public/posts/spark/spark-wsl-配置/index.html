<!doctype html><html lang=en dir=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="noindex, nofollow"><title>WSL 配置 Spark | CodeMist · 记录技术与生活</title><meta name=keywords content="WSL,Spark"><meta name=description content="这是一篇介绍使用 Windows WSL 配置 Spark 的教程，包含 Java、Hadoop、Spark 的安装与配置过程。"><meta name=author content="CodeMist"><link rel=canonical href=https://codeofwhite.github.io:1313/posts/spark/spark-wsl-%E9%85%8D%E7%BD%AE/><link crossorigin=anonymous href=/assets/css/stylesheet.4eeb2a64a3de0f36594052b43ee23799783a8ce4e9243cfe8aec759f323813e8.css integrity="sha256-TusqZKPeDzZZQFK0PuI3mXg6jOTpJDz+iux1nzI4E+g=" rel="preload stylesheet" as=style><link rel=icon href=https://codeofwhite.github.io:1313/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://codeofwhite.github.io:1313/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://codeofwhite.github.io:1313/favicon-32x32.png><link rel=apple-touch-icon href=https://codeofwhite.github.io:1313/apple-touch-icon.png><link rel=mask-icon href=https://codeofwhite.github.io:1313/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://codeofwhite.github.io:1313/posts/spark/spark-wsl-%E9%85%8D%E7%BD%AE/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://codeofwhite.github.io:1313/ accesskey=h title="CodeMist · 记录技术与生活 (Alt + H)">CodeMist · 记录技术与生活</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://codeofwhite.github.io:1313/posts/ title=文章><span>文章</span></a></li><li><a href=https://codeofwhite.github.io:1313/categories/bigdata/ title=大数据><span>大数据</span></a></li><li><a href=https://codeofwhite.github.io:1313/categories/ai/ title=AI><span>AI</span></a></li><li><a href=https://codeofwhite.github.io:1313/categories/daily-study/ title="学习 · 日常"><span>学习 · 日常</span></a></li><li><a href=https://codeofwhite.github.io:1313/about/ title=关于><span>关于</span></a></li><li><a href=https://codeofwhite.github.io:1313/search/ title="搜索 (Alt + /)" accesskey=/><span>搜索</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://codeofwhite.github.io:1313/>Home</a>&nbsp;»&nbsp;<a href=https://codeofwhite.github.io:1313/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">WSL 配置 Spark</h1><div class=post-meta><span title='2025-04-24 00:00:00 +0000 UTC'>2025-04-24</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;CodeMist</div></header><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#%e4%b8%80%e5%ae%89%e8%a3%85-wsl aria-label="一、安装 WSL">一、安装 WSL</a></li><li><a href=#%e4%ba%8c%e9%85%8d%e7%bd%ae-ssh%e5%8f%af%e9%80%89 aria-label="二、配置 SSH（可选）">二、配置 SSH（可选）</a></li><li><a href=#%e4%b8%89%e5%ae%89%e8%a3%85-java aria-label="三、安装 Java">三、安装 Java</a></li><li><a href=#%e5%9b%9b%e5%ae%89%e8%a3%85-hadoop aria-label="四、安装 Hadoop">四、安装 Hadoop</a><ul><li><a href=#%e4%bf%ae%e6%94%b9%e9%85%8d%e7%bd%ae%e6%96%87%e4%bb%b6 aria-label=修改配置文件>修改配置文件</a><ul><li><a href=#core-sitexml aria-label=core-site.xml>core-site.xml</a></li><li><a href=#hdfs-sitexml aria-label=hdfs-site.xml>hdfs-site.xml</a></li></ul></li><li><a href=#%e6%a0%bc%e5%bc%8f%e5%8c%96%e5%b9%b6%e5%90%af%e5%8a%a8-hadoop aria-label="格式化并启动 Hadoop">格式化并启动 Hadoop</a></li></ul></li><li><a href=#%e4%ba%94%e5%ae%89%e8%a3%85-spark aria-label="五、安装 Spark">五、安装 Spark</a><ul><li><a href=#%e9%85%8d%e7%bd%ae-spark-%e7%8e%af%e5%a2%83 aria-label="配置 Spark 环境">配置 Spark 环境</a></li></ul></li><li><a href=#%e5%85%ad%e8%bf%90%e8%a1%8c-spark-%e7%a4%ba%e4%be%8b%e7%a8%8b%e5%ba%8f aria-label="六、运行 Spark 示例程序">六、运行 Spark 示例程序</a><ul><ul><li><a href=#%e8%be%93%e5%87%ba%e7%a4%ba%e4%be%8b aria-label=输出示例：>输出示例：</a></li></ul></ul></li><li><a href=#%e4%b8%83spark-%e5%b8%b8%e7%94%a8%e7%95%8c%e9%9d%a2%e8%ae%bf%e9%97%ae%e5%9c%b0%e5%9d%80 aria-label="七、Spark 常用界面访问地址">七、Spark 常用界面访问地址</a></li><li><a href=#%e5%85%ab%e5%8f%82%e8%80%83%e9%93%be%e6%8e%a5 aria-label=八、参考链接>八、参考链接</a></li></ul></div></details></div><div class=post-content><p>这是一篇介绍使用 Windows WSL 配置 Spark 的教程，包含 Java、Hadoop、Spark 的安装与配置过程。</p><p><strong>提示：别用 root 用户！</strong></p><h1 id=一安装-wsl>一、安装 WSL<a hidden class=anchor aria-hidden=true href=#一安装-wsl>#</a></h1><p>首先在 Windows 上启用 WSL（推荐使用 WSL2）：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-powershell data-lang=powershell><span class=line><span class=cl><span class=n>wsl</span> <span class=p>-</span><span class=n>-install</span>
</span></span></code></pre></div><p>安装完成后，建议使用 <strong>Ubuntu</strong> 发行版，可在 Microsoft Store 搜索并安装。</p><hr><h1 id=二配置-ssh可选>二、配置 SSH（可选）<a hidden class=anchor aria-hidden=true href=#二配置-ssh可选>#</a></h1><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>sudo apt install openssh-server
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>cd</span> ~/.ssh/  <span class=c1># 若无该目录，可先执行 ssh localhost 初始化</span>
</span></span><span class=line><span class=cl>ssh-keygen -t rsa   <span class=c1># 一路回车即可</span>
</span></span><span class=line><span class=cl>cat id_rsa.pub &gt;&gt; authorized_keys
</span></span></code></pre></div><hr><h1 id=三安装-java>三、安装 Java<a hidden class=anchor aria-hidden=true href=#三安装-java>#</a></h1><p>使用 OpenJDK 8（与 Spark 和 Hadoop 高度兼容）：</p><ul><li>下载文件：<code>OpenJDK8U-jdk_x64_linux_hotspot_8u442b06.tar.gz</code></li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>mkdir -p ~/soft <span class=o>&amp;&amp;</span> <span class=nb>cd</span> ~/soft
</span></span><span class=line><span class=cl>tar -xvzf OpenJDK8U-jdk_x64_linux_hotspot_8u442b06.tar.gz
</span></span><span class=line><span class=cl>sudo mv jdk8u442-b06 /opt/java
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 设置环境变量</span>
</span></span><span class=line><span class=cl><span class=nb>echo</span> <span class=s1>&#39;export JAVA_HOME=/opt/java&#39;</span> &gt;&gt; ~/.bashrc
</span></span><span class=line><span class=cl><span class=nb>echo</span> <span class=s1>&#39;export PATH=$JAVA_HOME/bin:$PATH&#39;</span> &gt;&gt; ~/.bashrc
</span></span><span class=line><span class=cl><span class=nb>source</span> ~/.bashrc
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 验证安装</span>
</span></span><span class=line><span class=cl>java -version
</span></span></code></pre></div><hr><h1 id=四安装-hadoop>四、安装 Hadoop<a hidden class=anchor aria-hidden=true href=#四安装-hadoop>#</a></h1><ul><li>下载文件：<code>hadoop-3.4.1-src.tar.gz</code></li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nb>cd</span> ~/soft
</span></span><span class=line><span class=cl>tar -xvzf hadoop-3.4.1-src.tar.gz
</span></span><span class=line><span class=cl>sudo mv hadoop-3.4.1-src /opt/module/hadoop-3.4.1
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 设置环境变量</span>
</span></span><span class=line><span class=cl><span class=nb>echo</span> <span class=s1>&#39;export HADOOP_HOME=/opt/module/hadoop-3.4.1&#39;</span> &gt;&gt; ~/.bashrc
</span></span><span class=line><span class=cl><span class=nb>echo</span> <span class=s1>&#39;export PATH=$HADOOP_HOME/bin:$PATH&#39;</span> &gt;&gt; ~/.bashrc
</span></span><span class=line><span class=cl><span class=nb>source</span> ~/.bashrc
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 验证安装</span>
</span></span><span class=line><span class=cl>hadoop version
</span></span></code></pre></div><h2 id=修改配置文件>修改配置文件<a hidden class=anchor aria-hidden=true href=#修改配置文件>#</a></h2><p><img alt="alt text" loading=lazy src=/images/image2.png></p><h3 id=core-sitexml><code>core-site.xml</code><a hidden class=anchor aria-hidden=true href=#core-sitexml>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-xml data-lang=xml><span class=line><span class=cl><span class=nt>&lt;configuration&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;property&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;name&gt;</span>hadoop.tmp.dir<span class=nt>&lt;/name&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;value&gt;</span>file:/opt/module/hadoop-3.4.1/tmp<span class=nt>&lt;/value&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;description&gt;</span>Abase for other temporary directories.<span class=nt>&lt;/description&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;/property&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;property&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;name&gt;</span>fs.defaultFS<span class=nt>&lt;/name&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;value&gt;</span>hdfs://localhost:9000<span class=nt>&lt;/value&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;/property&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c>&lt;!--
</span></span></span><span class=line><span class=cl><span class=c> 配置该属性，可以方便使用当前用户在 Hadoop UI界面进行 CRUD 操作
</span></span></span><span class=line><span class=cl><span class=c> &lt;value&gt;选项应替换为你的 username
</span></span></span><span class=line><span class=cl><span class=c>--&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;property&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;name&gt;</span>hadooop.http.staticuser.user<span class=nt>&lt;/name&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;value&gt;</span>zhj20<span class=nt>&lt;/value&gt;</span> # 这边换成你的用户名
</span></span><span class=line><span class=cl>  <span class=nt>&lt;/property&gt;</span>
</span></span><span class=line><span class=cl><span class=nt>&lt;/configuration&gt;</span>
</span></span></code></pre></div><h3 id=hdfs-sitexml><code>hdfs-site.xml</code><a hidden class=anchor aria-hidden=true href=#hdfs-sitexml>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-xml data-lang=xml><span class=line><span class=cl><span class=nt>&lt;configuration&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;property&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;name&gt;</span>dfs.namenode.name.dir<span class=nt>&lt;/name&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;value&gt;</span>file:///opt/module/hadoop-3.4.1/hadoop_data/hdfs/namenode<span class=nt>&lt;/value&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;/property&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;property&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;name&gt;</span>dfs.datanode.data.dir<span class=nt>&lt;/name&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;value&gt;</span>file:///opt/module/hadoop-3.4.1/hadoop_data/hdfs/datanode<span class=nt>&lt;/value&gt;</span>
</span></span><span class=line><span class=cl><span class=nt>&lt;/property&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;property&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;name&gt;</span>dfs.replication<span class=nt>&lt;/name&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;value&gt;</span>1<span class=nt>&lt;/value&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;/property&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;property&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;name&gt;</span>dfs.namenode.checkpoint.dir<span class=nt>&lt;/name&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;value&gt;</span>/opt/module/hadoop-3.4.1/tmp/dfs/namesecondary<span class=nt>&lt;/value&gt;</span>
</span></span><span class=line><span class=cl><span class=nt>&lt;/property&gt;</span>
</span></span><span class=line><span class=cl><span class=nt>&lt;property&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;name&gt;</span>dfs.namenode.rpc-address<span class=nt>&lt;/name&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;value&gt;</span>localhost:9000<span class=nt>&lt;/value&gt;</span>
</span></span><span class=line><span class=cl><span class=nt>&lt;/property&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nt>&lt;/configuration&gt;</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-xml data-lang=xml><span class=line><span class=cl><span class=nt>&lt;configuration&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;property&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;name&gt;</span>yarn.resourcemanager.hostname<span class=nt>&lt;/name&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;value&gt;</span>localhost<span class=nt>&lt;/value&gt;</span> <span class=c>&lt;!-- 或者 &#39;localhost&#39; --&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;/property&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=c>&lt;!-- nodemanager 本地资源路径 --&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;property&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;name&gt;</span>yarn.nodemanager.local-dirs<span class=nt>&lt;/name&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;value&gt;</span>/opt/module/hadoop-3.4.1/hadoop_data/nm-local-dir<span class=nt>&lt;/value&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;/property&gt;</span>
</span></span><span class=line><span class=cl>  <span class=c>&lt;!-- nodemanager 运行时日志路径 --&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;property&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;name&gt;</span>yarn.nodemanager.log-dirs<span class=nt>&lt;/name&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;value&gt;</span>/opt/module/hadoop-3.4.1/hadoop_data/logs<span class=nt>&lt;/value&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;/property&gt;</span>
</span></span><span class=line><span class=cl>    <span class=c>&lt;!-- 指定 ResourceManager 地址 --&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;property&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;name&gt;</span>yarn.resourcemanager.address<span class=nt>&lt;/name&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;value&gt;</span>codeofwhite:8032<span class=nt>&lt;/value&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;/property&gt;</span>
</span></span><span class=line><span class=cl>    <span class=c>&lt;!-- 启动 ResourceManager web UI 地址 --&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;property&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;name&gt;</span>yarn.resourcemanager.webapp.address<span class=nt>&lt;/name&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;value&gt;</span>codeofwhite:8088<span class=nt>&lt;/value&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;/property&gt;</span>
</span></span><span class=line><span class=cl><span class=c>&lt;!-- Site specific YARN configuration properties --&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;property&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;name&gt;</span>yarn.nodemanager.aux-services<span class=nt>&lt;/name&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;value&gt;</span>mapreduce_shuffle<span class=nt>&lt;/value&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;/property&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;property&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;name&gt;</span>yarn.log.dir<span class=nt>&lt;/name&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;value&gt;</span>/opt/module/hadoop-3.4.1/logs<span class=nt>&lt;/value&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;/property&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;property&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;name&gt;</span>yarn.nodemanager.resource.memory-mb<span class=nt>&lt;/name&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;value&gt;</span>4096<span class=nt>&lt;/value&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;/property&gt;</span>
</span></span><span class=line><span class=cl><span class=nt>&lt;/configuration&gt;</span>
</span></span></code></pre></div><h2 id=格式化并启动-hadoop>格式化并启动 Hadoop<a hidden class=anchor aria-hidden=true href=#格式化并启动-hadoop>#</a></h2><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nb>cd</span> /opt/module/hadoop-3.2.3
</span></span><span class=line><span class=cl>./bin/hdfs namenode -format
</span></span><span class=line><span class=cl>./sbin/start-dfs.sh
</span></span></code></pre></div><p>访问地址：<a href=http://localhost:9870>http://localhost:9870</a></p><hr><h1 id=五安装-spark>五、安装 Spark<a hidden class=anchor aria-hidden=true href=#五安装-spark>#</a></h1><ul><li>下载文件：<code>spark-3.5.1-bin-hadoop3.tgz</code></li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nb>cd</span> /opt/software
</span></span><span class=line><span class=cl>tar -zxvf spark-3.5.1-bin-hadoop3.tgz -C ../module
</span></span></code></pre></div><h2 id=配置-spark-环境>配置 Spark 环境<a hidden class=anchor aria-hidden=true href=#配置-spark-环境>#</a></h2><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nb>cd</span> /opt/module/spark-3.5.1-bin-hadoop3
</span></span><span class=line><span class=cl>cp conf/spark-env.sh.template conf/spark-env.sh
</span></span><span class=line><span class=cl>vim conf/spark-env.sh
</span></span></code></pre></div><p>添加以下内容：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nb>export</span> <span class=nv>SPARK_DIST_CLASSPATH</span><span class=o>=</span><span class=k>$(</span>/opt/module/hadoop-3.4.1/bin/hadoop classpath<span class=k>)</span>
</span></span></code></pre></div><hr><h1 id=六运行-spark-示例程序>六、运行 Spark 示例程序<a hidden class=anchor aria-hidden=true href=#六运行-spark-示例程序>#</a></h1><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nb>cd</span> /opt/module/spark-3.5.1-bin-hadoop3
</span></span><span class=line><span class=cl>./bin/run-example SparkPi
</span></span></code></pre></div><h3 id=输出示例>输出示例：<a hidden class=anchor aria-hidden=true href=#输出示例>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>Pi is roughly 3.1451557257786287
</span></span></code></pre></div><p>说明 Spark 运行成功。</p><hr><h1 id=七spark-常用界面访问地址>七、Spark 常用界面访问地址<a hidden class=anchor aria-hidden=true href=#七spark-常用界面访问地址>#</a></h1><table><thead><tr><th>服务</th><th>端口</th><th>说明</th></tr></thead><tbody><tr><td>Spark UI</td><td>4040</td><td>默认 shell 执行时激活</td></tr><tr><td>Hadoop NameNode UI</td><td>9870</td><td>Hadoop 文件系统界面</td></tr></tbody></table><hr><h1 id=八参考链接>八、参考链接<a hidden class=anchor aria-hidden=true href=#八参考链接>#</a></h1><ul><li><a href=https://blog.csdn.net/Milv_xx/article/details/134365873>CSDN 博客参考</a></li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=https://codeofwhite.github.io:1313/tags/wsl/>WSL</a></li><li><a href=https://codeofwhite.github.io:1313/tags/spark/>Spark</a></li></ul><nav class=paginav><a class=prev href=https://codeofwhite.github.io:1313/posts/spark/wsl-%E6%90%AD%E5%BB%BA-spark-debug/><span class=title>« Prev</span><br><span>WSL 下搭建 Spark 调试环境指南</span>
</a><a class=next href=https://codeofwhite.github.io:1313/posts/my-first-post/><span class=title>Next »</span><br><span>My First Blog</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2026 <a href=https://codeofwhite.github.io:1313/>CodeMist · 记录技术与生活</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>