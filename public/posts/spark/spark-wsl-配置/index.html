<!DOCTYPE html>
<html lang="zh-cn">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>WSL 配置 Spark | CodeMist · 记录技术与生活</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="这是一篇介绍使用 Windows WSL 配置 Spark 的教程，包含 Java、Hadoop、Spark 的安装与配置过程。">
    <meta name="generator" content="Hugo 0.152.2">
    
    
    
      <meta name="robots" content="index, follow">
    
    <meta name="author" content="CodeMist">
    

    
<link rel="stylesheet" href="/ananke/css/main.min.efe4d852f731d5d1fbb87718387202a97aafd768cdcdaed0662bbe6982e91824.css" >




    


    
      

    

    

    
      <link rel="canonical" href="https://codemist.org/posts/spark/spark-wsl-%E9%85%8D%E7%BD%AE/">
    

    <meta property="og:url" content="https://codemist.org/posts/spark/spark-wsl-%E9%85%8D%E7%BD%AE/">
  <meta property="og:site_name" content="CodeMist · 记录技术与生活">
  <meta property="og:title" content="WSL 配置 Spark">
  <meta property="og:description" content="这是一篇介绍使用 Windows WSL 配置 Spark 的教程，包含 Java、Hadoop、Spark 的安装与配置过程。">
  <meta property="og:locale" content="zh_cn">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2025-04-24T00:00:00+00:00">
    <meta property="article:modified_time" content="2025-04-24T00:00:00+00:00">
    <meta property="article:tag" content="WSL">
    <meta property="article:tag" content="Spark">

  <meta itemprop="name" content="WSL 配置 Spark">
  <meta itemprop="description" content="这是一篇介绍使用 Windows WSL 配置 Spark 的教程，包含 Java、Hadoop、Spark 的安装与配置过程。">
  <meta itemprop="datePublished" content="2025-04-24T00:00:00+00:00">
  <meta itemprop="dateModified" content="2025-04-24T00:00:00+00:00">
  <meta itemprop="wordCount" content="307">
  <meta itemprop="keywords" content="WSL,Spark">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="WSL 配置 Spark">
  <meta name="twitter:description" content="这是一篇介绍使用 Windows WSL 配置 Spark 的教程，包含 Java、Hadoop、Spark 的安装与配置过程。">

      
    
	
  </head><body class="ma0 avenir bg-near-white production">

    
   
  

  <header>
    <div class="bg-gray">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l center items-center justify-between">
    <a href="/" class="f3 fw2 hover-white white-90 dib no-underline">
      
        CodeMist · 记录技术与生活
      
    </a>
    <div class="flex-l items-center">
      

      
        <ul class="pl0 mr3">
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/" title="首页 page">
              首页
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/posts/" title="文章汇集 page">
              文章汇集
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/categories/bigdata/" title="大数据开发笔记 page">
              大数据开发笔记
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/categories/ai/" title="AI page">
              AI
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/categories/daily-study/" title="日常和学习 page">
              日常和学习
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/about/" title="关于 page">
              关于
            </a>
          </li>
          
        </ul>
      
      <div class="ananke-socials"></div>

    </div>
  </div>
</nav>

    </div>
  </header>



    <main class="pb7" role="main">
      
  
  
  <article class="flex-l mw8 center ph3 flex-wrap justify-between">
    <header class="mt4 w-100">
      <aside class="instapaper_ignoref b helvetica tracked ttu">
          
        Posts
      </aside><div id="sharing" class="mt3 ananke-socials"></div>
<h1 class="f1 athelas mt3 mb1">WSL 配置 Spark</h1>
      
      <p class="tracked"><strong>CodeMist</strong>
      </p>
      
      
      
      <time class="f6 mv4 dib tracked" datetime="2025-04-24T00:00:00Z">April 24, 2025</time>
      

      
      
        <span class="f6 mv4 dib tracked"> - 2 minutes read </span>
        <span class="f6 mv4 dib tracked"> - 307 words </span>
      
    </header>
    <div class="nested-copy-line-height lh-copy serif f4 nested-links text-light pr4-l w-two-thirds-l"><p>这是一篇介绍使用 Windows WSL 配置 Spark 的教程，包含 Java、Hadoop、Spark 的安装与配置过程。</p>
<p><strong>提示：别用 root 用户！</strong></p>
<h1 id="一安装-wsl">一、安装 WSL</h1>
<p>首先在 Windows 上启用 WSL（推荐使用 WSL2）：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-powershell" data-lang="powershell"><span class="line"><span class="cl"><span class="n">wsl</span> <span class="p">-</span><span class="n">-install</span>
</span></span></code></pre></div><p>安装完成后，建议使用 <strong>Ubuntu</strong> 发行版，可在 Microsoft Store 搜索并安装。</p>
<hr>
<h1 id="二配置-ssh可选">二、配置 SSH（可选）</h1>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">sudo apt install openssh-server
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nb">cd</span> ~/.ssh/  <span class="c1"># 若无该目录，可先执行 ssh localhost 初始化</span>
</span></span><span class="line"><span class="cl">ssh-keygen -t rsa   <span class="c1"># 一路回车即可</span>
</span></span><span class="line"><span class="cl">cat id_rsa.pub &gt;&gt; authorized_keys
</span></span></code></pre></div><hr>
<h1 id="三安装-java">三、安装 Java</h1>
<p>使用 OpenJDK 8（与 Spark 和 Hadoop 高度兼容）：</p>
<ul>
<li>下载文件：<code>OpenJDK8U-jdk_x64_linux_hotspot_8u442b06.tar.gz</code></li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">mkdir -p ~/soft <span class="o">&amp;&amp;</span> <span class="nb">cd</span> ~/soft
</span></span><span class="line"><span class="cl">tar -xvzf OpenJDK8U-jdk_x64_linux_hotspot_8u442b06.tar.gz
</span></span><span class="line"><span class="cl">sudo mv jdk8u442-b06 /opt/java
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 设置环境变量</span>
</span></span><span class="line"><span class="cl"><span class="nb">echo</span> <span class="s1">&#39;export JAVA_HOME=/opt/java&#39;</span> &gt;&gt; ~/.bashrc
</span></span><span class="line"><span class="cl"><span class="nb">echo</span> <span class="s1">&#39;export PATH=$JAVA_HOME/bin:$PATH&#39;</span> &gt;&gt; ~/.bashrc
</span></span><span class="line"><span class="cl"><span class="nb">source</span> ~/.bashrc
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 验证安装</span>
</span></span><span class="line"><span class="cl">java -version
</span></span></code></pre></div><hr>
<h1 id="四安装-hadoop">四、安装 Hadoop</h1>
<ul>
<li>下载文件：<code>hadoop-3.4.1-src.tar.gz</code></li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="nb">cd</span> ~/soft
</span></span><span class="line"><span class="cl">tar -xvzf hadoop-3.4.1-src.tar.gz
</span></span><span class="line"><span class="cl">sudo mv hadoop-3.4.1-src /opt/module/hadoop-3.4.1
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 设置环境变量</span>
</span></span><span class="line"><span class="cl"><span class="nb">echo</span> <span class="s1">&#39;export HADOOP_HOME=/opt/module/hadoop-3.4.1&#39;</span> &gt;&gt; ~/.bashrc
</span></span><span class="line"><span class="cl"><span class="nb">echo</span> <span class="s1">&#39;export PATH=$HADOOP_HOME/bin:$PATH&#39;</span> &gt;&gt; ~/.bashrc
</span></span><span class="line"><span class="cl"><span class="nb">source</span> ~/.bashrc
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 验证安装</span>
</span></span><span class="line"><span class="cl">hadoop version
</span></span></code></pre></div><h2 id="修改配置文件">修改配置文件</h2>
<p><img src="/images/image2.png" alt="alt text"></p>
<h3 id="core-sitexml"><code>core-site.xml</code></h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-xml" data-lang="xml"><span class="line"><span class="cl"><span class="nt">&lt;configuration&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;property&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;name&gt;</span>hadoop.tmp.dir<span class="nt">&lt;/name&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;value&gt;</span>file:/opt/module/hadoop-3.4.1/tmp<span class="nt">&lt;/value&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;description&gt;</span>Abase for other temporary directories.<span class="nt">&lt;/description&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;/property&gt;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;property&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;name&gt;</span>fs.defaultFS<span class="nt">&lt;/name&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;value&gt;</span>hdfs://localhost:9000<span class="nt">&lt;/value&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;/property&gt;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c">&lt;!--
</span></span></span><span class="line"><span class="cl"><span class="c"> 配置该属性，可以方便使用当前用户在 Hadoop UI界面进行 CRUD 操作
</span></span></span><span class="line"><span class="cl"><span class="c"> &lt;value&gt;选项应替换为你的 username
</span></span></span><span class="line"><span class="cl"><span class="c">--&gt;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;property&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;name&gt;</span>hadooop.http.staticuser.user<span class="nt">&lt;/name&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;value&gt;</span>zhj20<span class="nt">&lt;/value&gt;</span> # 这边换成你的用户名
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;/property&gt;</span>
</span></span><span class="line"><span class="cl"><span class="nt">&lt;/configuration&gt;</span>
</span></span></code></pre></div><h3 id="hdfs-sitexml"><code>hdfs-site.xml</code></h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-xml" data-lang="xml"><span class="line"><span class="cl"><span class="nt">&lt;configuration&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;property&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;name&gt;</span>dfs.namenode.name.dir<span class="nt">&lt;/name&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;value&gt;</span>file:///opt/module/hadoop-3.4.1/hadoop_data/hdfs/namenode<span class="nt">&lt;/value&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;/property&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;property&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;name&gt;</span>dfs.datanode.data.dir<span class="nt">&lt;/name&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;value&gt;</span>file:///opt/module/hadoop-3.4.1/hadoop_data/hdfs/datanode<span class="nt">&lt;/value&gt;</span>
</span></span><span class="line"><span class="cl"><span class="nt">&lt;/property&gt;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;property&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;name&gt;</span>dfs.replication<span class="nt">&lt;/name&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;value&gt;</span>1<span class="nt">&lt;/value&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;/property&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;property&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;name&gt;</span>dfs.namenode.checkpoint.dir<span class="nt">&lt;/name&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;value&gt;</span>/opt/module/hadoop-3.4.1/tmp/dfs/namesecondary<span class="nt">&lt;/value&gt;</span>
</span></span><span class="line"><span class="cl"><span class="nt">&lt;/property&gt;</span>
</span></span><span class="line"><span class="cl"><span class="nt">&lt;property&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;name&gt;</span>dfs.namenode.rpc-address<span class="nt">&lt;/name&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;value&gt;</span>localhost:9000<span class="nt">&lt;/value&gt;</span>
</span></span><span class="line"><span class="cl"><span class="nt">&lt;/property&gt;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nt">&lt;/configuration&gt;</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-xml" data-lang="xml"><span class="line"><span class="cl"><span class="nt">&lt;configuration&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;property&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;name&gt;</span>yarn.resourcemanager.hostname<span class="nt">&lt;/name&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;value&gt;</span>localhost<span class="nt">&lt;/value&gt;</span> <span class="c">&lt;!-- 或者 &#39;localhost&#39; --&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;/property&gt;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="c">&lt;!-- nodemanager 本地资源路径 --&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;property&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;name&gt;</span>yarn.nodemanager.local-dirs<span class="nt">&lt;/name&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;value&gt;</span>/opt/module/hadoop-3.4.1/hadoop_data/nm-local-dir<span class="nt">&lt;/value&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;/property&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="c">&lt;!-- nodemanager 运行时日志路径 --&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;property&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;name&gt;</span>yarn.nodemanager.log-dirs<span class="nt">&lt;/name&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;value&gt;</span>/opt/module/hadoop-3.4.1/hadoop_data/logs<span class="nt">&lt;/value&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;/property&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="c">&lt;!-- 指定 ResourceManager 地址 --&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;property&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;name&gt;</span>yarn.resourcemanager.address<span class="nt">&lt;/name&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;value&gt;</span>codeofwhite:8032<span class="nt">&lt;/value&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;/property&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="c">&lt;!-- 启动 ResourceManager web UI 地址 --&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;property&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;name&gt;</span>yarn.resourcemanager.webapp.address<span class="nt">&lt;/name&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;value&gt;</span>codeofwhite:8088<span class="nt">&lt;/value&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;/property&gt;</span>
</span></span><span class="line"><span class="cl"><span class="c">&lt;!-- Site specific YARN configuration properties --&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;property&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;name&gt;</span>yarn.nodemanager.aux-services<span class="nt">&lt;/name&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;value&gt;</span>mapreduce_shuffle<span class="nt">&lt;/value&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;/property&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;property&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;name&gt;</span>yarn.log.dir<span class="nt">&lt;/name&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;value&gt;</span>/opt/module/hadoop-3.4.1/logs<span class="nt">&lt;/value&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;/property&gt;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;property&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;name&gt;</span>yarn.nodemanager.resource.memory-mb<span class="nt">&lt;/name&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;value&gt;</span>4096<span class="nt">&lt;/value&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;/property&gt;</span>
</span></span><span class="line"><span class="cl"><span class="nt">&lt;/configuration&gt;</span>
</span></span></code></pre></div><h2 id="格式化并启动-hadoop">格式化并启动 Hadoop</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="nb">cd</span> /opt/module/hadoop-3.2.3
</span></span><span class="line"><span class="cl">./bin/hdfs namenode -format
</span></span><span class="line"><span class="cl">./sbin/start-dfs.sh
</span></span></code></pre></div><p>访问地址：<a href="http://localhost:9870">http://localhost:9870</a></p>
<hr>
<h1 id="五安装-spark">五、安装 Spark</h1>
<ul>
<li>下载文件：<code>spark-3.5.1-bin-hadoop3.tgz</code></li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="nb">cd</span> /opt/software
</span></span><span class="line"><span class="cl">tar -zxvf spark-3.5.1-bin-hadoop3.tgz -C ../module
</span></span></code></pre></div><h2 id="配置-spark-环境">配置 Spark 环境</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="nb">cd</span> /opt/module/spark-3.5.1-bin-hadoop3
</span></span><span class="line"><span class="cl">cp conf/spark-env.sh.template conf/spark-env.sh
</span></span><span class="line"><span class="cl">vim conf/spark-env.sh
</span></span></code></pre></div><p>添加以下内容：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="nb">export</span> <span class="nv">SPARK_DIST_CLASSPATH</span><span class="o">=</span><span class="k">$(</span>/opt/module/hadoop-3.4.1/bin/hadoop classpath<span class="k">)</span>
</span></span></code></pre></div><hr>
<h1 id="六运行-spark-示例程序">六、运行 Spark 示例程序</h1>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="nb">cd</span> /opt/module/spark-3.5.1-bin-hadoop3
</span></span><span class="line"><span class="cl">./bin/run-example SparkPi
</span></span></code></pre></div><h3 id="输出示例">输出示例：</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-text" data-lang="text"><span class="line"><span class="cl">Pi is roughly 3.1451557257786287
</span></span></code></pre></div><p>说明 Spark 运行成功。</p>
<hr>
<h1 id="七spark-常用界面访问地址">七、Spark 常用界面访问地址</h1>
<table>
  <thead>
      <tr>
          <th>服务</th>
          <th>端口</th>
          <th>说明</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>Spark UI</td>
          <td>4040</td>
          <td>默认 shell 执行时激活</td>
      </tr>
      <tr>
          <td>Hadoop NameNode UI</td>
          <td>9870</td>
          <td>Hadoop 文件系统界面</td>
      </tr>
  </tbody>
</table>
<hr>
<h1 id="八参考链接">八、参考链接</h1>
<ul>
<li><a href="https://blog.csdn.net/Milv_xx/article/details/134365873">CSDN 博客参考</a></li>
</ul><ul class="pa0">
  
   <li class="list di">
     <a href="/tags/wsl/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">WSL</a>
   </li>
  
   <li class="list di">
     <a href="/tags/spark/" class="link f5 grow br-pill ba ph3 pv2 mb2 dib black sans-serif no-underline">Spark</a>
   </li>
  
</ul>
<div class="mt6 instapaper_ignoref">
      
      
      </div>
    </div>

    <aside class="w-30-l mt6-l">




</aside>

  </article>

    </main>
    <footer class="bg-gray bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white white-70 dn dib-ns pv2 ph3 no-underline" href="https://codemist.org/" >
    &copy;  CodeMist · 记录技术与生活 2025 
  </a>
    <div><div class="ananke-socials"></div>
</div>
  </div>
</footer>


<div style="margin-top: 10px; color: #666; font-size: 14px;">
  总访问量：<span id="busuanzi_value_site_pv"></span> 次 | 
  访客数：<span id="busuanzi_value_site_uv"></span> 人
</div>

<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  </body>
</html>
