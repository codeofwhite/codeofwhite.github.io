[{"content":"Windows ä¸Š k8s å¯åŠ¨å¡åœ¨ Starting çš„ä¸€ä¸ªè§£å†³æ–¹æ¡ˆã€‚\n1 æŒ‚ä¸ªæ¢¯å­ è¿™ä¸ªä¸ç”¨å¤šè¯´é­”æ³•ä¸€ä¸‹å°±è¡Œ\n2 è‡ªå·±å…ˆæŠŠ k8s çš„é•œåƒæ‹‰ä¸‹æ¥ # ä½ çš„ K8s ç‰ˆæœ¬ $K8S_VERSION=\u0026#34;v1.32.4\u0026#34; # å¯¹åº”ä¾èµ–é•œåƒç‰ˆæœ¬ï¼ˆè‡ªå·±æŸ¥ä¸€ä¸‹è‡ªå·±ä»€ä¹ˆç‰ˆæœ¬ï¼‰ $ETCD_VERSION=\u0026#34;3.5.16-0\u0026#34; $COREDNS_VERSION=\u0026#34;v1.11.1\u0026#34; $PAUSE_VERSION=\u0026#34;3.9\u0026#34; # ä»é˜¿é‡Œäº‘æ‹‰å–é•œåƒ docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-apiserver:$K8S_VERSION docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-controller-manager:$K8S_VERSION docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-scheduler:$K8S_VERSION docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:$K8S_VERSION docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/pause:$PAUSE_VERSION docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/etcd:$ETCD_VERSION docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:$COREDNS_VERSION ç»™é•œåƒæ‰“é»˜è®¤æ ‡ç­¾ # ç»™é•œåƒæ‰“ä¸Š K8s å¯åŠ¨æ—¶é»˜è®¤æŸ¥æ‰¾çš„æ ‡ç­¾ï¼ˆregistry.k8s.io å‰ç¼€ï¼‰ docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kube-apiserver:$K8S_VERSION registry.k8s.io/kube-apiserver:$K8S_VERSION docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kube-controller-manager:$K8S_VERSION registry.k8s.io/kube-controller-manager:$K8S_VERSION docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kube-scheduler:$K8S_VERSION registry.k8s.io/kube-scheduler:$K8S_VERSION docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:$K8S_VERSION registry.k8s.io/kube-proxy:$K8S_VERSION docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/pause:$PAUSE_VERSION registry.k8s.io/pause:$PAUSE_VERSION docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/etcd:$ETCD_VERSION registry.k8s.io/etcd:$ETCD_VERSION docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:$COREDNS_VERSION registry.k8s.io/coredns/coredns:$COREDNS_VERSION æœ€åä¸€æ­¥ é‡å¯ docker desktop å¯åŠ¨ k8s å¤§åŠŸå‘Šæˆ ","permalink":"https://codeofwhite.github.io/posts/k8s/%E8%A7%A3%E5%86%B3-docker-desktop-k8s-%E5%90%AF%E5%8A%A8%E6%97%B6%E9%97%B4%E9%95%BF%E7%9A%84%E9%97%AE%E9%A2%98/","summary":"\u003cp\u003eWindows ä¸Š k8s å¯åŠ¨å¡åœ¨ Starting çš„ä¸€ä¸ªè§£å†³æ–¹æ¡ˆã€‚\u003c/p\u003e","title":"è§£å†³ Docker Desktop K8S å¯åŠ¨æ—¶é—´é•¿çš„é—®é¢˜"},{"content":"æœ¬æ–‡ä»‹ç»ä¸€ä¸ªæœ€å°å¯è¿è¡Œçš„ Change Data Capture (CDC) æ¼”ç¤ºé¡¹ç›®ï¼Œå®ç° MySQL æ•°æ®åº“å˜æ›´åˆ° Kafka çš„å®æ—¶åŒæ­¥ã€‚é¡¹ç›®åŒ…å«ä»¥ä¸‹æ ¸å¿ƒç»„ä»¶ï¼š\nDocker Compose é…ç½®ï¼šå¯åŠ¨ MySQLã€Kafkaã€Zookeeperã€Debezium Connect å’Œ Kafka UI\næ•°æ®åº“åˆå§‹åŒ–è„šæœ¬ï¼šåˆ›å»ºæµ‹è¯•è¡¨å’Œåˆå§‹æ•°æ®\nè¿æ¥å™¨æ³¨å†Œè„šæœ¬ï¼šé…ç½® Debezium MySQL Connector\né¡¹ç›®ç»“æ„ cdc-demo/ â”œâ”€â”€ docker-compose.yml # å®¹å™¨ç¼–æ’é…ç½® â”œâ”€â”€ init.sql # æ•°æ®åº“åˆå§‹åŒ–è„šæœ¬ â””â”€â”€ register-connector.sh # Debezium è¿æ¥å™¨æ³¨å†Œè„šæœ¬ æ ¸å¿ƒé…ç½® docker-compose.yml version: \u0026#39;3.7\u0026#39; services: zookeeper: image: confluentinc/cp-zookeeper:7.3.0 environment: ZOOKEEPER_CLIENT_PORT: 2181 ZOOKEEPER_TICK_TIME: 2000 kafka: image: confluentinc/cp-kafka:7.3.0 depends_on: - zookeeper ports: - \u0026#34;9092:9092\u0026#34; environment: KAFKA_BROKER_ID: 1 KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181 KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092 KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1 mysql: image: mysql:8.0 container_name: mysql ports: - \u0026#34;3306:3306\u0026#34; environment: MYSQL_ROOT_PASSWORD: root MYSQL_DATABASE: testdb volumes: - ./init.sql:/docker-entrypoint-initdb.d/init.sql command: [ \u0026#34;--server-id=223344\u0026#34;, \u0026#34;--log-bin=mysql-bin\u0026#34;, \u0026#34;--binlog-format=ROW\u0026#34;, \u0026#34;--binlog-row-image=FULL\u0026#34; ] connect: image: debezium/connect:2.4.1.Final ports: - \u0026#34;8083:8083\u0026#34; depends_on: - kafka - mysql environment: BOOTSTRAP_SERVERS: kafka:9092 GROUP_ID: 1 CONFIG_STORAGE_TOPIC: debezium_config OFFSET_STORAGE_TOPIC: debezium_offsets STATUS_STORAGE_TOPIC: debezium_status KEY_CONVERTER_SCHEMAS_ENABLE: \u0026#34;false\u0026#34; VALUE_CONVERTER_SCHEMAS_ENABLE: \u0026#34;false\u0026#34; CONNECT_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter CONNECT_REST_ADVERTISED_HOST_NAME: connect CONNECT_PLUGIN_PATH: /kafka/connect kafka-ui: image: provectuslabs/kafka-ui:latest ports: - \u0026#34;8080:8080\u0026#34; environment: KAFKA_CLUSTERS_0_NAME: local KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092 init.sql (MySQL åˆå§‹æ•°æ®) CREATE TABLE IF NOT EXISTS testdb.test_table ( id INT PRIMARY KEY AUTO_INCREMENT, name VARCHAR(100), age INT ); INSERT INTO testdb.test_table (name, age) VALUES (\u0026#39;Alice\u0026#39;, 30), (\u0026#39;Bob\u0026#39;, 25); register-connector.sh (æ³¨å†Œ Debezium MySQL Connector) #!/bin/bash curl -X POST http://localhost:8083/connectors -H \u0026#34;Content-Type: application/json\u0026#34; -d \u0026#39;{ \u0026#34;name\u0026#34;: \u0026#34;mysql-cdc-connector\u0026#34;, \u0026#34;config\u0026#34;: { \u0026#34;connector.class\u0026#34;: \u0026#34;io.debezium.connector.mysql.MySqlConnector\u0026#34;, \u0026#34;database.hostname\u0026#34;: \u0026#34;mysql\u0026#34;, \u0026#34;database.port\u0026#34;: \u0026#34;3306\u0026#34;, \u0026#34;database.user\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;database.password\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;database.server.id\u0026#34;: \u0026#34;223344\u0026#34;, \u0026#34;topic.prefix\u0026#34;: \u0026#34;mysql-server\u0026#34;, \u0026#34;database.server.name\u0026#34;: \u0026#34;mysql-server\u0026#34;, \u0026#34;database.include.list\u0026#34;: \u0026#34;testdb\u0026#34;, \u0026#34;table.include.list\u0026#34;: \u0026#34;testdb.test_table\u0026#34;, \u0026#34;include.schema.changes\u0026#34;: \u0026#34;false\u0026#34;, \u0026#34;snapshot.mode\u0026#34;: \u0026#34;initial\u0026#34;, \u0026#34;schema.history.internal.kafka.bootstrap.servers\u0026#34;: \u0026#34;kafka:9092\u0026#34;, \u0026#34;schema.history.internal.kafka.topic\u0026#34;: \u0026#34;schema-changes.testdb\u0026#34; } }\u0026#39; è¿™ä¸ªé…ç½®ä¼šåœ¨ Kafka ä¸­åˆ›å»ºä¸¤ä¸ªä¸åŒç”¨é€”çš„ topicï¼Œå®ƒä»¬åˆ†åˆ«æ˜¯ï¼š\nTopic è¯´æ˜ 1. schema-changes.testdb è¿™æ˜¯ Debezium å†…éƒ¨ä½¿ç”¨çš„ topicï¼Œè®°å½•çš„æ˜¯ MySQL è¡¨ç»“æ„ï¼ˆschemaï¼‰å˜åŒ–å†å²ã€‚\nç”±é…ç½®é¡¹æ§åˆ¶ï¼š\n\u0026#34;schema.history.internal.kafka.topic\u0026#34;: \u0026#34;schema-changes.testdb\u0026#34; å­˜ä»€ä¹ˆï¼Ÿ\nè¡¨åˆ›å»ºã€å­—æ®µå˜æ›´ã€ä¸»é”®å˜åŒ–ç­‰ç»“æ„æ€§ä¿¡æ¯ Kafka Connect ç”¨å®ƒæ¥ æ¢å¤ä»»åŠ¡çŠ¶æ€ã€ç¡®ä¿å¹‚ç­‰æ€§ é»˜è®¤ä¸ä¼šæ˜¾ç¤ºåœ¨ä¸šåŠ¡æ¶ˆè´¹ä¸­ï¼Œä½ ä¸€èˆ¬ä¸éœ€è¦å…³å¿ƒè¿™ä¸ª topic çš„å†…å®¹\nğŸ›  é€šå¸¸ partition=1ï¼Œreplication=1 å°±å¤Ÿäº†\n2. mysql-server.testdb.test_table è¿™æ˜¯ ä¸šåŠ¡æ•°æ® topicï¼Œå³ä½ çœŸæ­£è¦æ¶ˆè´¹çš„ CDCï¼ˆå˜æ›´æ•°æ®æ•è·ï¼‰æ•°æ®æµã€‚\næ„æˆæ–¹å¼ï¼š\n\u0026#34;topic.prefix\u0026#34;: \u0026#34;mysql-server\u0026#34; \u0026#34;database.include.list\u0026#34;: \u0026#34;testdb\u0026#34; \u0026#34;table.include.list\u0026#34;: \u0026#34;testdb.test_table\u0026#34; æœ€ç»ˆ topic = prefix + . + database + . + table â†’ mysql-server.testdb.test_table\nå­˜ä»€ä¹ˆï¼Ÿ\nINSERT / UPDATE / DELETE æ“ä½œå¯¹åº”çš„æ•°æ®å˜æ›´è®°å½• æ¯”å¦‚ UPDATE age = 32ï¼Œä¼šè®°å½• before å’Œ after å€¼ Kafka UI ä¸­æˆ‘ä»¬å…³æ³¨çš„å°±æ˜¯è¿™ä¸ª topic\nä½¿ç”¨æ­¥éª¤ # 1. å¯åŠ¨æœåŠ¡ docker-compose up -d # 2. ç­‰å¾…æœåŠ¡å¯åŠ¨ï¼ˆå°¤å…¶æ˜¯ MySQL å’Œ Kafkaï¼‰ # 3. æ³¨å†Œ CDC connector bash register-connector.sh # 4. æµè§ˆ Kafka UI æŸ¥çœ‹æ¶ˆæ¯ (http://localhost:8080/ui)ï¼ŒæŸ¥çœ‹ topic: mysql-server.testdb.test_table æµ‹è¯•å¢é‡æ•°æ®åŒæ­¥\ndocker exec -it mysql mysql -uroot -proot USE testdb; INSERT INTO test_table (name, age) VALUES (\u0026#39;Charlie\u0026#39;, 40); UPDATE test_table SET age = 31 WHERE name = \u0026#39;Alice\u0026#39;; DELETE FROM test_table WHERE name = \u0026#39;Bob\u0026#39;; å¸¸è§é—®é¢˜å¤„ç† é—®é¢˜ï¼šç¼ºå°‘ Kafka Topic # åœ¨å®¹å™¨é‡Œæ‰§è¡Œä»¥ä¸‹å‘½ä»¤ docker exec -it \u0026lt;kafka-container-id\u0026gt; bash # åˆ›å»º topicï¼ˆåå­—è¦å’Œé…ç½®ä¸­ä¸€è‡´ï¼‰ kafka-topics --bootstrap-server localhost:9092 --create \\ --topic schema-changes.testdb --replication-factor 1 --partitions 1 ","permalink":"https://codeofwhite.github.io/posts/debezium/%E5%9F%BA%E4%BA%8E-debezium-%E7%9A%84-cdc-%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E5%AE%9E%E8%B7%B5/","summary":"\u003cp\u003eæœ¬æ–‡ä»‹ç»ä¸€ä¸ªæœ€å°å¯è¿è¡Œçš„ Change Data Capture (CDC) æ¼”ç¤ºé¡¹ç›®ï¼Œå®ç° MySQL æ•°æ®åº“å˜æ›´åˆ° Kafka çš„å®æ—¶åŒæ­¥ã€‚é¡¹ç›®åŒ…å«ä»¥ä¸‹æ ¸å¿ƒç»„ä»¶ï¼š\u003c/p\u003e\n\u003cp\u003eDocker Compose é…ç½®ï¼šå¯åŠ¨ MySQLã€Kafkaã€Zookeeperã€Debezium Connect å’Œ Kafka UI\u003c/p\u003e\n\u003cp\u003eæ•°æ®åº“åˆå§‹åŒ–è„šæœ¬ï¼šåˆ›å»ºæµ‹è¯•è¡¨å’Œåˆå§‹æ•°æ®\u003c/p\u003e\n\u003cp\u003eè¿æ¥å™¨æ³¨å†Œè„šæœ¬ï¼šé…ç½® Debezium MySQL Connector\u003c/p\u003e","title":"åŸºäº Debezium çš„ CDC æ•°æ®åŒæ­¥å®è·µ"},{"content":"WSL ä¸­ Flink é‡å¯ä¸¢å¤± Catalog ç­‰è®°å½•é—®é¢˜\nFlink SQL Client æ¯æ¬¡å¯åŠ¨æ—¶ã€Œcatalogï¼ˆç›®å½•ï¼‰ã€tableï¼ˆè¡¨ï¼‰ã€ç­‰å¯¹è±¡æ¶ˆå¤±ï¼Œä¸»è¦æ˜¯å› ä¸º é»˜è®¤çš„ catalog å’Œ database é…ç½®æ˜¯ä¸´æ—¶çš„ï¼Œä¸”æ²¡æœ‰æŒä¹…åŒ–åˆ°å¤–éƒ¨å­˜å‚¨æˆ–é…ç½®æ–‡ä»¶ä¸­ã€‚ä»¥ä¸‹æ˜¯é€ æˆè¿™ç§ç°è±¡çš„åŸå› åŠè§£å†³æ–¹æ¡ˆã€‚\nåŸå› åˆ†æ é»˜è®¤ä½¿ç”¨å†…å­˜ Catalogï¼ˆdefault_catalogï¼‰\nFlink SQL Client é»˜è®¤å¯åŠ¨æ—¶ä½¿ç”¨å†…å­˜ä¸­çš„ default_catalog.default_databaseï¼Œæ‰€æœ‰é€šè¿‡ SQL åˆ›å»ºçš„è¡¨ï¼ˆå¦‚ CREATE TABLEï¼‰é»˜è®¤åªå­˜åœ¨äºè¿™ä¸ªä¼šè¯ä¸­ã€‚ å½“ä½ å…³é—­ Flink SQL Client åï¼Œå†…å­˜ä¸­çš„ catalog/table å°±ä¼šä¸¢å¤±ã€‚ æ²¡æœ‰ä½¿ç”¨æŒä¹…åŒ– Catalogï¼ˆå¦‚ Hive Catalog / JDBC Catalog / FileSystem Catalogï¼‰\nåªæœ‰å½“ä½ é…ç½®å¹¶ä½¿ç”¨äº†ä¸€ä¸ªå¤–éƒ¨æŒä¹…åŒ–çš„ catalogï¼ˆå¦‚ Hive Metastoreã€JDBC Catalog æˆ–å­˜å‚¨åœ¨æœ¬åœ°/è¿œç¨‹æ–‡ä»¶ç³»ç»Ÿçš„ FileSystem Catalogï¼‰æ—¶ï¼Œè¡¨ç»“æ„æ‰ä¼šä¿å­˜åœ¨å¤–éƒ¨ã€‚ æœªä½¿ç”¨ .sql è„šæœ¬æˆ– YAML åˆå§‹åŒ–é…ç½®\nå¦‚æœä½ æ²¡æœ‰ä½¿ç”¨åˆå§‹åŒ– SQL æ–‡ä»¶æˆ– YAML é…ç½®æ–‡ä»¶ï¼ŒSQL Client å¯åŠ¨æ—¶ä¸ä¼šè‡ªåŠ¨åŠ è½½ä½ ä¹‹å‰çš„è¡¨å®šä¹‰ã€‚ è§£å†³æ–¹æ¡ˆ æ–¹æ³•ä¸€ï¼šä½¿ç”¨æŒä¹…åŒ– Catalog ç¤ºä¾‹ï¼šä½¿ç”¨ HiveCatalog CREATE CATALOG my_hive WITH ( \u0026#39;type\u0026#39; = \u0026#39;hive\u0026#39;, \u0026#39;default-database\u0026#39; = \u0026#39;default\u0026#39;, \u0026#39;hive-conf-dir\u0026#39; = \u0026#39;/path/to/hive/conf\u0026#39; ); USE CATALOG my_hive; ä½¿ç”¨ HiveCatalog åï¼Œæ‰€æœ‰è¡¨ä¼šæ³¨å†Œè¿› Hive Metastoreï¼Œä¸‹æ¬¡é‡å¯ä¾ç„¶å­˜åœ¨ã€‚\næ–¹æ³•äºŒï¼šä½¿ç”¨ FileSystem Catalogï¼ˆè½»é‡çº§æ–¹æ¡ˆï¼‰ CREATE CATALOG my_fs WITH ( \u0026#39;type\u0026#39; = \u0026#39;filesystem\u0026#39;, \u0026#39;default-database\u0026#39; = \u0026#39;mydb\u0026#39;, \u0026#39;warehouse\u0026#39; = \u0026#39;file:///path/to/catalog_dir\u0026#39; ); åˆ›å»ºçš„è¡¨ä¼šå†™å…¥æœ¬åœ°/è¿œç¨‹ç›®å½•ï¼ˆå¦‚ HDFSï¼‰ã€‚ é‡å¯ Flink SQL Client å¹¶é‡æ–° USE CATALOG my_fs åå¯å†æ¬¡è®¿é—®ã€‚ æ–¹æ³•ä¸‰ï¼šé…ç½®åˆå§‹åŒ–è„šæœ¬ å¯ä»¥åœ¨ Flink SQL Client å¯åŠ¨æ—¶ä½¿ç”¨åˆå§‹åŒ– SQL è„šæœ¬æˆ– YAML é…ç½®ï¼š\né…ç½® sql-client-defaults.yamlï¼š catalogs: - name: my_hive type: hive hive-conf-dir: /path/to/hive/conf æ”¾å…¥ ${FLINK_HOME}/conf/sql-client-defaults.yaml ä¸­ï¼Œæ¯æ¬¡å¯åŠ¨ SQL Client æ—¶è‡ªåŠ¨åŠ è½½ã€‚ ","permalink":"https://codeofwhite.github.io/posts/flink/flink-%E9%87%8D%E5%90%AF%E4%B8%A2%E5%A4%B1-catalog-%E7%AD%89%E8%AE%B0%E5%BD%95%E9%97%AE%E9%A2%98/","summary":"\u003cp\u003eWSL ä¸­ Flink é‡å¯ä¸¢å¤± Catalog ç­‰è®°å½•é—®é¢˜\u003c/p\u003e","title":"Flink é‡å¯ä¸¢å¤± Catalog ç­‰è®°å½•é—®é¢˜"},{"content":"éƒ¨ç½² Spark Streaming å®ç°æµè®¡ç®—çš„å¸¸è§é”™è¯¯ã€‚\næŠ¥é”™åŸå› \njava.lang.NoClassDefFoundError: org/apache/spark/kafka010/KafkaConfigUpdater è¿™é‡ŒæŠ¥é”™çš„åŸå› æ˜¯å°‘äº†ä¸€äº› jar åŒ…ï¼Œç„¶åæœ‰æ—¶å€™å°±ç®—ä½ åŠ äº† jar åŒ…ï¼Œä¹Ÿæœ‰å¯èƒ½ spark ä¼šæ‰¾ä¸åˆ° jar åŒ…åœ¨å“ªã€‚å¯¹åº”çš„ jar åŒ…ç›´æ¥åœ¨ç”²éª¨æ–‡çš„å®˜ç½‘ä¸‹å°±å¯ä»¥äº†ã€‚\næˆ‘è¿™é‡Œçš„å¤„ç†æ–¹å¼æ˜¯åœ¨ config æŒ‡æ˜ jar åŒ…åœ¨å“ªé‡Œã€‚\n# åˆ›å»º SparkSession spark = SparkSession.builder \\ .appName(\u0026#34;KafkaSparkStreamingExample\u0026#34;) \\ .config(\u0026#34;spark.jars\u0026#34;, \u0026#34;file:///opt/module/spark-3.5.1-bin-hadoop3/jars/spark-sql-kafka-0-10_2.12-3.5.1.jar,file:///opt/module/spark-3.5.1-bin-hadoop3/jars/kafka-clients-2.7.2.jar,file:///opt/module/spark-3.5.1-bin-hadoop3/jars/spark-token-provider-kafka-0-10_2.12-3.5.3.jar,file:///opt/module/spark-3.5.1-bin-hadoop3/jars/commons-pool2-2.12.0.jar\u0026#34;) \\ .getOrCreate() æœ€åæˆåŠŸè§£å†³é—®é¢˜\n","permalink":"https://codeofwhite.github.io/posts/spark/spark-streaming-%E6%8A%A5%E9%94%99%E8%AE%B0%E5%BD%95/","summary":"\u003cp\u003eéƒ¨ç½² Spark Streaming å®ç°æµè®¡ç®—çš„å¸¸è§é”™è¯¯ã€‚\u003c/p\u003e","title":"Spark Streaming æŠ¥é”™è®°å½•"},{"content":"åœ¨ Windows WSL ä¸Šéƒ¨ç½² Kafka\nå®‰è£… Kafka cd /opt/module wget https://archive.apache.org/dist/kafka/3.6.1/kafka_2.13-3.6.1.tgz # è§£å‹ tar -zxvf kafka_2.13-3.6.1.tgz # æ”¹å mv kafka_2.13-3.6.1 kafka å¿«é€Ÿéƒ¨ç½² # åˆ›å»º topic ./bin/kafka-topics.sh --create --topic test-topic --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1 # æ£€æŸ¥ topic æ˜¯å¦åˆ›å»ºæˆåŠŸ ./bin/kafka-topics.sh --list --bootstrap-server localhost:9092 # å¯åŠ¨ç”Ÿäº§è€… ./bin/kafka-console-producer.sh --topic test-topic --bootstrap-server localhost:9092 # åœ¨å¦ä¸€ä¸ªç»ˆç«¯å¯åŠ¨æ¶ˆè´¹è€… ./bin/kafka-console-consumer.sh --topic test-topic --from-beginning --bootstrap-server localhost:9092 Python ä¸Šè¿›è¡Œæµ‹è¯• pip install kafka-python producer.py\nfrom kafka import KafkaProducer producer = KafkaProducer(bootstrap_servers=\u0026#39;localhost:9092\u0026#39;) for i in range(5): message = f\u0026#34;Message {i}\u0026#34; producer.send(\u0026#39;test-topic\u0026#39;, message.encode(\u0026#39;utf-8\u0026#39;)) print(f\u0026#34;Sent: {message}\u0026#34;) producer.flush() consumer.py\nfrom kafka import KafkaConsumer consumer = KafkaConsumer( \u0026#39;test-topic\u0026#39;, bootstrap_servers=\u0026#39;localhost:9092\u0026#39;, auto_offset_reset=\u0026#39;earliest\u0026#39;, group_id=\u0026#39;my-group\u0026#39;) for message in consumer: print(f\u0026#34;Received: {message.value.decode(\u0026#39;utf-8\u0026#39;)}\u0026#34;) ","permalink":"https://codeofwhite.github.io/posts/kafka/wsl-kafka-%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/","summary":"\u003cp\u003eåœ¨ Windows WSL ä¸Šéƒ¨ç½² Kafka\u003c/p\u003e","title":"WSL Kafka å®‰è£…æ•™ç¨‹"},{"content":"wsl Flink paimon å®è·µ\nä½¿ç”¨ Apache Paimon + Apache Flink + WSLï¼ˆWindows Subsystem for Linuxï¼‰å¯ä»¥é«˜æ•ˆå®ç°å¤§è§„æ¨¡æ•°æ®æ¹–å®æ—¶å¤„ç†å’Œåˆ†æã€‚ä»¥ä¸‹æ˜¯è¿™ä¸‰è€…ç»“åˆä½¿ç”¨çš„ æœ€ä½³å®è·µæŒ‡å—ï¼ŒåŒ…æ‹¬å¼€å‘ç¯å¢ƒé…ç½®ã€ä½œä¸šè¿è¡Œã€è¡¨æ“ä½œä¸è°ƒè¯•å»ºè®®ç­‰æ–¹é¢ã€‚\nä¸€ã€å‡†å¤‡WSL 1. å®‰è£… WSL å’Œ Ubuntu ç¡®ä¿ä½¿ç”¨çš„æ˜¯ WSL2ï¼Œæ¨èå®‰è£… Ubuntu 20.04/22.04ï¼š\nwsl --install -d Ubuntu 2. å®‰è£… Java å’Œ Maven sudo apt update sudo apt install openjdk-17-jdk maven -y 3. å®‰è£… Flink wget https://downloads.apache.org/flink/flink-1.17.1/flink-1.17.1-bin-scala_2.12.tgz tar -xvzf flink-1.17.1-bin-scala_2.12.tgz 4. å®‰è£… Paimon å¯ç›´æ¥ä½¿ç”¨é¢„ç¼–è¯‘çš„ paimon-flink jarï¼Œä¹Ÿå¯æºç ç¼–è¯‘ã€‚\næ¨èç‰ˆæœ¬ï¼šPaimon 0.6+ ä¸‹è½½äºŒè¿›åˆ¶ï¼š wget https://archive.apache.org/dist/paimon/paimon-0.6.1/apache-paimon-0.6.1-bin.tar.gz è§£å‹åï¼Œå°† paimon-flink-*.jar æ”¾å…¥ Flink çš„ lib/ ç›®å½•ä¸­ã€‚ äºŒã€Flink + Paimon çš„é›†æˆè¦ç‚¹ 1. é…ç½® FLINK_HOME export FLINK_HOME=~/flink-1.17.1 export PATH=$FLINK_HOME/bin:$PATH 2. å¯åŠ¨ Flink é›†ç¾¤ï¼ˆæœ¬åœ°æ¨¡å¼ï¼‰ start-cluster.sh 3. å¯åŠ¨ SQL å®¢æˆ·ç«¯ï¼ˆè¿™é‡Œæˆ‘æ¨èä½¿ç”¨ SQL CLIï¼‰ sql-client.sh å¤åˆ¶ jar åŒ…åˆ°ä½ çš„ flink é‡Œé¢ï¼ˆéœ€è¦ä¸‹è½½ hadoopï¼‰ cp /opt/module/hadoop-3.4.1/share/hadoop/common/hadoop-common-*.jar . cp /opt/module/hadoop-3.4.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-*.jar . cp /opt/module/hadoop-3.4.1/share/hadoop/hdfs/hadoop-hdfs-*.jar . cp /opt/module/hadoop-3.4.1/share/hadoop/common/hadoop-auth-*.jar . 4. åŠ è½½ Paimon Catalog CREATE CATALOG paimon WITH ( \u0026#39;type\u0026#39; = \u0026#39;paimon\u0026#39;, \u0026#39;warehouse\u0026#39; = \u0026#39;file:///home/your_user/paimon-warehouse\u0026#39; ); USE CATALOG paimon; ä¸‰ã€è¡¨å®šä¹‰ä¸æœ€ä½³å®è·µ 1. åˆ›å»ºè¡¨ï¼ˆç¤ºä¾‹ï¼šä»¥æµæ•°æ®å†™å…¥ï¼‰ CREATE TABLE user_events ( user_id BIGINT, event_type STRING, event_time TIMESTAMP(3), WATERMARK FOR event_time AS event_time - INTERVAL \u0026#39;5\u0026#39; SECOND ) PARTITIONED BY (event_type) WITH ( \u0026#39;bucket\u0026#39; = \u0026#39;2\u0026#39;, \u0026#39;file.format\u0026#39; = \u0026#39;parquet\u0026#39;, \u0026#39;sink.parallelism\u0026#39; = \u0026#39;2\u0026#39; ); 2. æ•°æ®å†™å…¥ç¤ºä¾‹ ä½¿ç”¨ DataStream æˆ– SQL æ’å…¥ï¼š\nINSERT INTO user_events SELECT user_id, event_type, event_time FROM source_table; å››ã€å®æ—¶æŸ¥è¯¢ï¼ˆStreaming Queryï¼‰ ä½¿ç”¨ Flink SQL æˆ– Flink DataStream è¯»å– Paimon è¡¨ï¼š\n-- å®æ—¶è¯»å–ï¼ˆChangeLog Modeï¼‰ SELECT * FROM user_events /*+ OPTIONS(\u0026#39;scan.mode\u0026#39;=\u0026#39;incremental\u0026#39;) */; æœ€ä½³å®è·µå‚æ•°è¯´æ˜ï¼š\nscan.mode=incrementalï¼šè¯»å–å¢é‡å˜åŒ–ã€‚ log.system=noneï¼šæ— æ—¥å¿—ç³»ç»Ÿï¼Œå¯é€‰ kafka/noneã€‚ ","permalink":"https://codeofwhite.github.io/posts/flink/wsl-%E6%9E%84%E5%BB%BA-flink-+-paimon/","summary":"\u003cp\u003ewsl Flink paimon å®è·µ\u003c/p\u003e","title":"WSL æ„å»º Flink + Paimon å®è·µ"},{"content":"åœ¨å¼€å‘ç¯å¢ƒä¸­ä½¿ç”¨ Spark + Hadoop æ—¶ï¼Œç»å¸¸ä¼šé‡åˆ°ä¸€äº›â€œé‡å¯å°±å´©â€â€œè«åå…¶å¦™æŠ¥é”™â€çš„æƒ…å†µã€‚è¿™ç¯‡æ–‡ç« æ•´ç†äº†ä¸€äº›å¸¸è§çš„å‘å’Œæœ€ä½³å®è·µï¼Œå¸Œæœ›èƒ½å¸®ä½ ä¼˜é›…åœ°å¯åŠ¨å’Œå…³é—­ Spark/Hadoop é›†ç¾¤ã€‚\nå¯åŠ¨ä¸å…³é—­å‘½ä»¤é€ŸæŸ¥ å…ˆæ¥ä¸€æ³¢æœ€åŸºæœ¬çš„æ“ä½œï¼š\nå¯åŠ¨å‘½ä»¤ cd /opt/module/hadoop-3.4.1 ./sbin/start-dfs.sh ./sbin/start-yarn.sh ä¼˜é›…å…³é—­ ./sbin/stop-dfs.sh ./sbin/stop-yarn.sh ä¸ºä»€ä¹ˆé‡å¯åä¼šæŠ¥é”™ï¼Ÿ ç®€çŸ­å›ç­”ï¼š å¾ˆå¯èƒ½æ˜¯æ²¡æœ‰â€œä¼˜é›…â€åœ°å…³é—­é›†ç¾¤ï¼Œæˆ–è€…æ‰‹åŠ¨æ‰§è¡Œäº†ä¸è¯¥æ‰§è¡Œçš„æ“ä½œï¼ˆæ¯”å¦‚ -formatï¼‰ã€‚\nç³»ç»Ÿå…³æœºå‰å¦‚æœæ²¡æœ‰æ‰§è¡Œ stop-dfs.shï¼Œå¯èƒ½å¯¼è‡´ NameNode ä¸ DataNode çŠ¶æ€ä¸ä¸€è‡´ï¼Œä»è€Œåœ¨ä¸‹æ¬¡å¯åŠ¨æ—¶æŠ¥é”™ã€‚\nåŸç†ç®€å•èŠèŠ Hadoop çš„ HDFS ä½¿ç”¨ä¸€ä¸ªå« ClusterID çš„æ ‡è¯†æ¥ç¡®è®¤å„èŠ‚ç‚¹æ˜¯å¦å±äºåŒä¸€ä¸ªé›†ç¾¤ï¼š\nNameNode å¯åŠ¨æ—¶ä¼šæ£€æŸ¥è‡ªå·±çš„ ClusterIDã€‚ DataNode å¯åŠ¨æ—¶ä¹Ÿä¼šè¯»å–æœ¬åœ°å­˜å‚¨çš„ ClusterIDã€‚ å¦‚æœæ‰§è¡Œäº†ï¼š\nhdfs namenode -format ä¼šé‡æ–°ç”Ÿæˆä¸€ä¸ªæ–°çš„ ClusterID å¹¶å†™å…¥ NameNode çš„ç›®å½•ã€‚ä½†æ­¤æ—¶ï¼ŒDataNode çš„ç›®å½•è¿˜å­˜ç€æ—§çš„ ClusterIDï¼Œå°±ä¼šå‡ºç°ç±»ä¼¼è¿™æ ·çš„é”™è¯¯ï¼š\nâ€œClusterID ä¸åŒ¹é…ï¼Œæ‹’ç»è¿æ¥ï¼â€\näºæ˜¯ä½ çœ‹åˆ°äº†ä¸€å¤§ä¸²å¯åŠ¨å¤±è´¥çš„å¼‚å¸¸å †æ ˆã€‚\nå¦‚ä½•é¿å…é¢‘ç¹æ¸…ç©ºæˆ–å‡ºé”™ï¼Ÿ æ–¹æ³•ä¸€ï¼šåˆ«é¢‘ç¹ format åªåœ¨ç¬¬ä¸€æ¬¡æ­å»ºç¯å¢ƒæ—¶æ‰§è¡Œä¸€æ¬¡ï¼š\nhdfs namenode -format ä¹‹åå†ä¹Ÿä¸ç”¨ã€‚ä¸è¦åŠ¨ä¸åŠ¨å°± formatï¼Œå¦åˆ™ä¹‹å‰çš„æ•°æ®ã€å…ƒä¿¡æ¯å…¨æ²¡äº†ï¼ŒDataNode ä¹Ÿä¼šæ‹’ç»å·¥ä½œã€‚\næ–¹æ³•äºŒï¼šå…³æœºå‰è®°å¾—ä¼˜é›…åœæœ é‡å¯ç”µè„‘å‰æ‰§è¡Œï¼š\n./sbin/stop-dfs.sh è¿™æ ·å¯ä»¥ç¡®ä¿æ‰€æœ‰èŠ‚ç‚¹æ­£å¸¸æ–­å¼€ï¼Œé¿å…çŠ¶æ€ä¸ä¸€è‡´ã€‚\næ–¹æ³•ä¸‰ï¼šå®šæœŸå¤‡ä»½æ•°æ®ç›®å½• å¦‚æœä½ ä¸æ”¾å¿ƒï¼Œå¯ä»¥å¤‡ä»½ Hadoop çš„æ•°æ®ç›®å½•ï¼š\ncp -r /opt/module/hadoop-3.4.1/hadoop_data ~/hadoop_data_backup å´©äº†ä¹Ÿèƒ½å¿«é€Ÿè¿˜åŸï¼š\ncp -r ~/hadoop_data_backup /opt/module/hadoop-3.4.1/hadoop_data æ–¹æ³•å››ï¼šä½¿ç”¨ Docker æˆ–è™šæ‹Ÿæœºå¿«ç…§ å¦‚æœä½ ç”¨çš„æ˜¯ Docker æˆ– VirtualBoxï¼Œå®Œå…¨å¯ä»¥åœ¨é…ç½®å¥½ç¯å¢ƒååšä¸ªå¿«ç…§ï¼Œæ¯æ¬¡å‡ºé—®é¢˜ç›´æ¥è¿˜åŸåˆ°â€œå¹²å‡€ç°åœºâ€ï¼Œå¼€å‘è°ƒè¯•ç‰¹åˆ«çœå¿ƒã€‚\n","permalink":"https://codeofwhite.github.io/posts/spark/spark-yarn-%E5%90%AF%E5%8A%A8%E4%B8%8E%E5%85%B3%E9%97%AD%E7%9A%84%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9%E6%80%BB%E7%BB%93/","summary":"\u003cp\u003eåœ¨å¼€å‘ç¯å¢ƒä¸­ä½¿ç”¨ Spark + Hadoop æ—¶ï¼Œç»å¸¸ä¼šé‡åˆ°ä¸€äº›â€œé‡å¯å°±å´©â€â€œè«åå…¶å¦™æŠ¥é”™â€çš„æƒ…å†µã€‚è¿™ç¯‡æ–‡ç« æ•´ç†äº†ä¸€äº›å¸¸è§çš„å‘å’Œæœ€ä½³å®è·µï¼Œå¸Œæœ›èƒ½å¸®ä½ ä¼˜é›…åœ°å¯åŠ¨å’Œå…³é—­ Spark/Hadoop é›†ç¾¤ã€‚\u003c/p\u003e","title":"Spark Yarn å¯åŠ¨ä¸å…³é—­çš„æ³¨æ„äº‹é¡¹æ€»ç»“"},{"content":"Spark MLlib ä¸ PyTorch å¯¹æ¯” 1. æ ¸å¿ƒå®šä½ Spark MLlibï¼šä¸“æ³¨åˆ†å¸ƒå¼å¤§æ•°æ®å¤„ç†ï¼Œé€‚åˆä¼ ç»Ÿæœºå™¨å­¦ä¹ ï¼ˆå¦‚å›å½’ã€èšç±»ï¼‰å’Œå¤§è§„æ¨¡æ•°æ®é¢„å¤„ç†ã€‚ PyTorchï¼šä¸“æ³¨æ·±åº¦å­¦ä¹ ï¼ˆå¦‚CNNã€RNNï¼‰ï¼Œæ”¯æŒåŠ¨æ€è®¡ç®—å›¾å’ŒGPUåŠ é€Ÿï¼Œé€‚åˆå¤æ‚æ¨¡å‹ç ”å‘ã€‚ 2. æ•°æ®å¤„ç† Sparkï¼šåŸºäºåˆ†å¸ƒå¼æ•°æ®é›†ï¼ˆRDD/DataFrameï¼‰ï¼Œé€‚åˆæ‰¹å¤„ç†å’Œæµå¼æ•°æ®ã€‚ PyTorchï¼šå•æœºä¸ºä¸»ï¼ˆæ”¯æŒåˆ†å¸ƒå¼æ‰©å±•ï¼‰ï¼Œé€šè¿‡DataLoaderé«˜æ•ˆåŠ è½½æ•°æ®ï¼Œé€‚åˆå°è§„æ¨¡é«˜ç»´æ•°æ®ï¼ˆå¦‚å›¾åƒã€æ–‡æœ¬ï¼‰ã€‚ 3. è®¡ç®—æ¨¡å‹ Sparkï¼šé™æ€è®¡ç®—å›¾ï¼Œé€‚åˆå›ºå®šæµç¨‹çš„åˆ†å¸ƒå¼è®¡ç®—ã€‚ PyTorchï¼šåŠ¨æ€è®¡ç®—å›¾ï¼Œçµæ´»è°ƒè¯•ï¼Œé€‚åˆå¿«é€Ÿè¿­ä»£ã€‚ 4. æ€§èƒ½ä¸æ‰©å±• Sparkï¼šä¾èµ–é›†ç¾¤è§„æ¨¡ï¼Œé€‚åˆæµ·é‡æ•°æ®æ‰¹å¤„ç†ã€‚ PyTorchï¼šä¾èµ–GPUåŠ é€Ÿï¼Œé€‚åˆæ·±åº¦å­¦ä¹ çš„é«˜æ€§èƒ½è®¡ç®—ã€‚ 5. é€‚ç”¨åœºæ™¯ é€‰Spark MLlibï¼šéœ€å¤„ç†TBçº§æ•°æ®æˆ–ä¼ ç»Ÿæœºå™¨å­¦ä¹ ä»»åŠ¡ã€‚ é€‰PyTorchï¼šéœ€è®­ç»ƒå¤æ‚ç¥ç»ç½‘ç»œæˆ–ç ”ç©¶æ–°æ¨¡å‹ã€‚ æ€»ç»“ï¼šä¸¤è€…äº’è¡¥â€”â€”Sparkå¤„ç†å¤§æ•°æ®ï¼ŒPyTorchæ·±è€•æ·±åº¦å­¦ä¹ ã€‚\n","permalink":"https://codeofwhite.github.io/posts/spark/spark-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E4%B8%8E-pytorch-%E5%88%86%E5%88%AB/","summary":"","title":"Spark æœºå™¨å­¦ä¹  ä¸ Pytorch åˆ†åˆ«"},{"content":"æˆ‘ä»¬ä¹‹å‰æ­å»ºçš„çœŸå®åˆ†å¸ƒå¼ç¯å¢ƒå…è®¸ä»»åŠ¡ï¼š\n./bin/spark-submit --master yarn ~/pyspark-project/test/word_count.py æ€»ç»“ ç›®çš„ æ¨èæ–¹å¼ æœ¬åœ°å¼€å‘ / è°ƒè¯• ä½¿ç”¨ VSCode è¿è¡Œ Python æ–‡ä»¶ï¼ˆæ¨èï¼‰ æ¨¡æ‹ŸçœŸå®è¿è¡Œ ä½¿ç”¨ spark-submit --master local[*] çœŸæ­£åˆ†å¸ƒå¼æäº¤ä»»åŠ¡ ä½¿ç”¨ spark-submit --master yarnï¼ˆéœ€è¦é…ç½® Hadoopï¼‰ è¯´æ˜ï¼š æœ¬åœ°å¼€å‘ / è°ƒè¯•ï¼šåœ¨å¼€å‘è¿‡ç¨‹ä¸­ï¼Œä½¿ç”¨ VSCode ç›´æ¥è¿è¡Œ Python æ–‡ä»¶å¯ä»¥å¿«é€Ÿè¿›è¡Œè°ƒè¯•ï¼Œé€‚åˆå°è§„æ¨¡æ•°æ®å’Œæµ‹è¯•ã€‚ æ¨¡æ‹ŸçœŸå®è¿è¡Œï¼šä½¿ç”¨ spark-submit --master local[*] å¯ä»¥åœ¨æœ¬åœ°æ¨¡æ‹Ÿåˆ†å¸ƒå¼è¿è¡Œï¼Œé€‚ç”¨äºå•æœºç¯å¢ƒä¸‹çš„æµ‹è¯•å’Œè°ƒè¯•ï¼Œ[*] è¡¨ç¤ºä½¿ç”¨æ‰€æœ‰å¯ç”¨çš„ CPU æ ¸å¿ƒã€‚ çœŸæ­£åˆ†å¸ƒå¼æäº¤ä»»åŠ¡ï¼šå½“ä½ å‡†å¤‡åœ¨çœŸå®çš„åˆ†å¸ƒå¼ç¯å¢ƒä¸­è¿è¡Œä»»åŠ¡æ—¶ï¼Œå¯ä»¥ä½¿ç”¨ spark-submit --master yarn å°†ä»»åŠ¡æäº¤åˆ° YARN é›†ç¾¤ï¼Œéœ€è¦äº‹å…ˆé…ç½® Hadoop é›†ç¾¤ã€‚ ","permalink":"https://codeofwhite.github.io/posts/spark/spark-%E7%9A%84%E5%87%A0%E7%A7%8D%E5%90%AF%E5%8A%A8%E6%96%B9%E5%BC%8F/","summary":"","title":"Spark çš„å‡ ç§å¯åŠ¨æ–¹å¼"},{"content":"è¿™æ˜¯ä¸€ç¯‡è®°å½•åœ¨ WSL ç¯å¢ƒä¸‹æ­å»º Spark è°ƒè¯•ç¯å¢ƒæ—¶é‡åˆ°çš„é—®é¢˜åŠå…¶è§£å†³æ–¹æ³•çš„åšå®¢ï¼Œæ–¹ä¾¿æ—¥åæ’é›·å¤ç”¨ã€‚\nBug 1ï¼šç”¨æˆ·æƒé™é—®é¢˜ å¯åŠ¨ Hadoop æ—¶å‡ºç°é”™è¯¯ï¼š\nERROR: namenode can only be executed by root. æ’æŸ¥åå‘ç°ï¼Œstart-dfs.sh è„šæœ¬ä¸­å¯¹æ‰§è¡Œç”¨æˆ·æœ‰é™åˆ¶ï¼ˆå¦‚ä¸‹å›¾ï¼‰ï¼Œå½“å‰ç”¨æˆ·é root æ—¶ä¼šæŠ¥é”™ï¼š\nè§£å†³æ–¹æ³•ï¼š\nä½¿ç”¨ root ç”¨æˆ·æ‰§è¡Œå¯åŠ¨è„šæœ¬ï¼Œæˆ– ä¿®æ”¹ start-dfs.sh ä¸­çš„ç”¨æˆ·æ ¡éªŒï¼ˆä»…å»ºè®®åœ¨å¼€å‘ç¯å¢ƒä½¿ç”¨ï¼‰ Bug 2ï¼šSSH æ— å¯†ç ç™»å½•å¤±è´¥ æŠ¥é”™ä¿¡æ¯ï¼š\nlocalhost: zhj20@localhost: Permission denied (publickey,password) è¯´æ˜ SSH æ— å¯†ç ç™»å½•æœªé…ç½®ï¼ŒHadoop å¯åŠ¨è¿‡ç¨‹ä¸­çš„å†…éƒ¨é€šä¿¡å¤±è´¥ã€‚\nè§£å†³æ­¥éª¤ï¼š\nç”Ÿæˆ SSH å¯†é’¥ï¼ˆè‹¥æ— ï¼‰\nssh-keygen -t rsa -P \u0026#39;\u0026#39; -f ~/.ssh/id_rsa é…ç½®å…¬é’¥è®¤è¯\ncat ~/.ssh/id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys chmod 600 ~/.ssh/authorized_keys éªŒè¯æ˜¯å¦èƒ½å…å¯†ç™»å½•\nssh localhost æˆåŠŸååº”è‡ªåŠ¨ç™»å½•ï¼Œæ— éœ€è¾“å…¥å¯†ç ï¼Œexit é€€å‡ºå³å¯ã€‚\nBug 3ï¼šYARN èŠ‚ç‚¹åˆ—è¡¨ä¸ºç©º æ‰§è¡Œ yarn node -list æ—¶æ— ä»»ä½•èŠ‚ç‚¹ã€‚\næ’æŸ¥æ–¹å‘ï¼š\nç¡®è®¤ ResourceManager å’Œ NodeManager æ˜¯å¦éƒ½å·²å¯åŠ¨ï¼ˆjps æŸ¥çœ‹ï¼‰ æ£€æŸ¥ yarn-site.xml é…ç½®æ˜¯å¦æ­£ç¡® æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶æ˜¯å¦æœ‰ç½‘ç»œè¿æ¥/ç«¯å£å¼‚å¸¸ Bug 4ï¼šNameNode å¯åŠ¨å¤±è´¥ï¼ˆEditLog å¼‚å¸¸ï¼‰ There appears to be a gap in the edit log. We expected txid 1, but got txid 113. åŸå› åˆ†æï¼š\nHadoop æ¢å¤ fsimage + editlog æ—¶å‘ç° txid åºå·ä¸è¿ç»­ï¼Œeditlog å¯èƒ½æŸåæˆ–ç¼ºå¤±ã€‚ è§£å†³æ–¹æ¡ˆï¼ˆæ— é‡è¦æ•°æ®æ—¶ï¼‰ï¼š\nhdfs namenode -format ./sbin/start-dfs.sh æ³¨æ„ï¼šæ­¤æ“ä½œä¼šæ¸…ç©º HDFS ä¸­çš„æ‰€æœ‰æ•°æ®ï¼Œä»…å»ºè®®åœ¨è°ƒè¯•æˆ–å¼€å‘ç¯å¢ƒä¸­ä½¿ç”¨ï¼\nBug 5ï¼šDataNode å¯åŠ¨å¤±è´¥ï¼Œæ— æ³•å†™å…¥å‰¯æœ¬ é”™è¯¯ä¿¡æ¯ï¼š\nFile ... could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running æ’æŸ¥é…ç½®ï¼š\ncat $HADOOP_HOME/etc/hadoop/hdfs-site.xml | grep -A 5 dfs.datanode.data.dir æ—¥å¿—æç¤ºï¼š\nIncompatible clusterIDs namenode clusterID = CID-018939f5... datanode clusterID = CID-659a4b77... è¯´æ˜ DataNode ä¿å­˜çš„ clusterID ä¸ NameNode ä¸ä¸€è‡´ã€‚\nè§£å†³åŠæ³•ï¼š\n# åœæ­¢ Hadoop ./sbin/stop-dfs.sh # æ¸…é™¤ DataNode æ•°æ®ï¼ˆä¸è¦åˆ  NameNode æ•°æ®ï¼ï¼‰ rm -rf /opt/module/hadoop-3.4.1/hadoop_data/hdfs/datanode/* # é‡å¯ ./sbin/start-dfs.sh # æŸ¥çœ‹æ˜¯å¦æ­£å¸¸å¯åŠ¨ jps å‚è€ƒé“¾æ¥ WSL é…ç½® Spark çš„å‘ï¼ˆChatGPT åˆ†äº«é¡µ 1ï¼‰ è°ƒè¯• HDFS NameNode å¯åŠ¨å¤±è´¥ï¼ˆChatGPT åˆ†äº«é¡µ 2ï¼‰ DataNode ClusterID ä¸ä¸€è‡´æ’æŸ¥è®°å½•ï¼ˆChatGPT åˆ†äº«é¡µ 3ï¼‰ ","permalink":"https://codeofwhite.github.io/posts/spark/wsl-%E4%B8%8B%E6%90%AD%E5%BB%BA-spark-%E8%B0%83%E8%AF%95%E7%8E%AF%E5%A2%83%E6%8C%87%E5%8D%97/","summary":"\u003cp\u003eè¿™æ˜¯ä¸€ç¯‡è®°å½•åœ¨ WSL ç¯å¢ƒä¸‹æ­å»º Spark è°ƒè¯•ç¯å¢ƒæ—¶é‡åˆ°çš„é—®é¢˜åŠå…¶è§£å†³æ–¹æ³•çš„åšå®¢ï¼Œæ–¹ä¾¿æ—¥åæ’é›·å¤ç”¨ã€‚\u003c/p\u003e","title":"WSL ä¸‹æ­å»º Spark è°ƒè¯•ç¯å¢ƒæŒ‡å—"},{"content":"è¿™æ˜¯ä¸€ç¯‡ä»‹ç»ä½¿ç”¨ Windows WSL é…ç½® Spark çš„æ•™ç¨‹ï¼ŒåŒ…å« Javaã€Hadoopã€Spark çš„å®‰è£…ä¸é…ç½®è¿‡ç¨‹ã€‚\næç¤ºï¼šåˆ«ç”¨ root ç”¨æˆ·ï¼\nä¸€ã€å®‰è£… WSL é¦–å…ˆåœ¨ Windows ä¸Šå¯ç”¨ WSLï¼ˆæ¨èä½¿ç”¨ WSL2ï¼‰ï¼š\nwsl --install å®‰è£…å®Œæˆåï¼Œå»ºè®®ä½¿ç”¨ Ubuntu å‘è¡Œç‰ˆï¼Œå¯åœ¨ Microsoft Store æœç´¢å¹¶å®‰è£…ã€‚\näºŒã€é…ç½® SSHï¼ˆå¯é€‰ï¼‰ sudo apt install openssh-server cd ~/.ssh/ # è‹¥æ— è¯¥ç›®å½•ï¼Œå¯å…ˆæ‰§è¡Œ ssh localhost åˆå§‹åŒ– ssh-keygen -t rsa # ä¸€è·¯å›è½¦å³å¯ cat id_rsa.pub \u0026gt;\u0026gt; authorized_keys ä¸‰ã€å®‰è£… Java ä½¿ç”¨ OpenJDK 8ï¼ˆä¸ Spark å’Œ Hadoop é«˜åº¦å…¼å®¹ï¼‰ï¼š\nä¸‹è½½æ–‡ä»¶ï¼šOpenJDK8U-jdk_x64_linux_hotspot_8u442b06.tar.gz mkdir -p ~/soft \u0026amp;\u0026amp; cd ~/soft tar -xvzf OpenJDK8U-jdk_x64_linux_hotspot_8u442b06.tar.gz sudo mv jdk8u442-b06 /opt/java # è®¾ç½®ç¯å¢ƒå˜é‡ echo \u0026#39;export JAVA_HOME=/opt/java\u0026#39; \u0026gt;\u0026gt; ~/.bashrc echo \u0026#39;export PATH=$JAVA_HOME/bin:$PATH\u0026#39; \u0026gt;\u0026gt; ~/.bashrc source ~/.bashrc # éªŒè¯å®‰è£… java -version å››ã€å®‰è£… Hadoop ä¸‹è½½æ–‡ä»¶ï¼šhadoop-3.4.1-src.tar.gz cd ~/soft tar -xvzf hadoop-3.4.1-src.tar.gz sudo mv hadoop-3.4.1-src /opt/module/hadoop-3.4.1 # è®¾ç½®ç¯å¢ƒå˜é‡ echo \u0026#39;export HADOOP_HOME=/opt/module/hadoop-3.4.1\u0026#39; \u0026gt;\u0026gt; ~/.bashrc echo \u0026#39;export PATH=$HADOOP_HOME/bin:$PATH\u0026#39; \u0026gt;\u0026gt; ~/.bashrc source ~/.bashrc # éªŒè¯å®‰è£… hadoop version ä¿®æ”¹é…ç½®æ–‡ä»¶ core-site.xml \u0026lt;configuration\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;hadoop.tmp.dir\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;file:/opt/module/hadoop-3.4.1/tmp\u0026lt;/value\u0026gt; \u0026lt;description\u0026gt;Abase for other temporary directories.\u0026lt;/description\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;fs.defaultFS\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;hdfs://localhost:9000\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!-- é…ç½®è¯¥å±æ€§ï¼Œå¯ä»¥æ–¹ä¾¿ä½¿ç”¨å½“å‰ç”¨æˆ·åœ¨ Hadoop UIç•Œé¢è¿›è¡Œ CRUD æ“ä½œ \u0026lt;value\u0026gt;é€‰é¡¹åº”æ›¿æ¢ä¸ºä½ çš„ username --\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;hadooop.http.staticuser.user\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;zhj20\u0026lt;/value\u0026gt; # è¿™è¾¹æ¢æˆä½ çš„ç”¨æˆ·å \u0026lt;/property\u0026gt; \u0026lt;/configuration\u0026gt; hdfs-site.xml \u0026lt;configuration\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.namenode.name.dir\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;file:///opt/module/hadoop-3.4.1/hadoop_data/hdfs/namenode\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.datanode.data.dir\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;file:///opt/module/hadoop-3.4.1/hadoop_data/hdfs/datanode\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.replication\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;1\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.namenode.checkpoint.dir\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;/opt/module/hadoop-3.4.1/tmp/dfs/namesecondary\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.namenode.rpc-address\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;localhost:9000\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;yarn.resourcemanager.hostname\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;localhost\u0026lt;/value\u0026gt; \u0026lt;!-- æˆ–è€… \u0026#39;localhost\u0026#39; --\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!-- nodemanager æœ¬åœ°èµ„æºè·¯å¾„ --\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;yarn.nodemanager.local-dirs\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;/opt/module/hadoop-3.4.1/hadoop_data/nm-local-dir\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!-- nodemanager è¿è¡Œæ—¶æ—¥å¿—è·¯å¾„ --\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;yarn.nodemanager.log-dirs\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;/opt/module/hadoop-3.4.1/hadoop_data/logs\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!-- æŒ‡å®š ResourceManager åœ°å€ --\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;yarn.resourcemanager.address\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;codeofwhite:8032\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!-- å¯åŠ¨ ResourceManager web UI åœ°å€ --\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;yarn.resourcemanager.webapp.address\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;codeofwhite:8088\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!-- Site specific YARN configuration properties --\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;yarn.nodemanager.aux-services\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;mapreduce_shuffle\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;yarn.log.dir\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;/opt/module/hadoop-3.4.1/logs\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;yarn.nodemanager.resource.memory-mb\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;4096\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/configuration\u0026gt; æ ¼å¼åŒ–å¹¶å¯åŠ¨ Hadoop cd /opt/module/hadoop-3.2.3 ./bin/hdfs namenode -format ./sbin/start-dfs.sh è®¿é—®åœ°å€ï¼šhttp://localhost:9870\näº”ã€å®‰è£… Spark ä¸‹è½½æ–‡ä»¶ï¼šspark-3.5.1-bin-hadoop3.tgz cd /opt/software tar -zxvf spark-3.5.1-bin-hadoop3.tgz -C ../module é…ç½® Spark ç¯å¢ƒ cd /opt/module/spark-3.5.1-bin-hadoop3 cp conf/spark-env.sh.template conf/spark-env.sh vim conf/spark-env.sh æ·»åŠ ä»¥ä¸‹å†…å®¹ï¼š\nexport SPARK_DIST_CLASSPATH=$(/opt/module/hadoop-3.4.1/bin/hadoop classpath) å…­ã€è¿è¡Œ Spark ç¤ºä¾‹ç¨‹åº cd /opt/module/spark-3.5.1-bin-hadoop3 ./bin/run-example SparkPi è¾“å‡ºç¤ºä¾‹ï¼š Pi is roughly 3.1451557257786287 è¯´æ˜ Spark è¿è¡ŒæˆåŠŸã€‚\nä¸ƒã€Spark å¸¸ç”¨ç•Œé¢è®¿é—®åœ°å€ æœåŠ¡ ç«¯å£ è¯´æ˜ Spark UI 4040 é»˜è®¤ shell æ‰§è¡Œæ—¶æ¿€æ´» Hadoop NameNode UI 9870 Hadoop æ–‡ä»¶ç³»ç»Ÿç•Œé¢ å…«ã€å‚è€ƒé“¾æ¥ CSDN åšå®¢å‚è€ƒ ","permalink":"https://codeofwhite.github.io/posts/spark/wsl-%E9%85%8D%E7%BD%AE-spark/","summary":"\u003cp\u003eè¿™æ˜¯ä¸€ç¯‡ä»‹ç»ä½¿ç”¨ Windows WSL é…ç½® Spark çš„æ•™ç¨‹ï¼ŒåŒ…å« Javaã€Hadoopã€Spark çš„å®‰è£…ä¸é…ç½®è¿‡ç¨‹ã€‚\u003c/p\u003e","title":"WSL é…ç½® Spark"},{"content":"å…³äºæˆ‘ Hiï¼Œä½œè€…æ¥è‡ªé‡åº†å¤§å­¦è½¯ä»¶å­¦é™¢æ•°æ®ç§‘å­¦ä¸å¤§æ•°æ®æŠ€æœ¯ä¸“ä¸šã€‚æ˜¯ä¸€åæ¥è‡ªæ¾³é—¨çš„æ¸¯æ¾³å°å­¦ç”Ÿã€‚\nå†™åšå®¢çš„åˆè¡·æ˜¯ï¼š\nè®°å½•è‡ªå·±è¸©è¿‡çš„å‘ï¼Œåˆ†äº«è‡ªå·±è§£å†³é—®é¢˜çš„æ€è·¯ è®°å½•æ¸¯æ¾³å°åœ¨å†…åœ°æ±‚å­¦çš„æ•…äº‹ å¦‚æœä½ åœ¨æˆ‘çš„åšå®¢ä¸­å‘ç°äº†é”™è¯¯ï¼Œæˆ–è€…æœ‰æ›´å¥½çš„å»ºè®®ï¼Œæ¬¢è¿éšæ—¶è”ç³»æˆ‘ï¼Œæˆ‘ä¼šè®¤çœŸå¯¹å¾…æ¯ä¸€ä¸ªåé¦ˆã€‚\nè”ç³»æˆ‘ å¦‚æœä½ å¯¹æˆ‘çš„åšå®¢å†…å®¹æ„Ÿå…´è¶£ï¼Œæˆ–è€…æœ‰ä»»ä½•é—®é¢˜å’Œå»ºè®®ï¼Œæ¬¢è¿é€šè¿‡ä»¥ä¸‹æ–¹å¼äº¤æµï¼š\nå¾®ä¿¡/QQï¼š1363180320 ç”µå­é‚®ä»¶ï¼š1363180320@qq.com æœŸå¾…ä¸ä½ çš„äº¤æµå’Œåˆä½œï¼\n","permalink":"https://codeofwhite.github.io/about/","summary":"\u003ch2 id=\"å…³äºæˆ‘\"\u003eå…³äºæˆ‘\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"ä½œè€…çš„å¸¸ç”¨å¤´åƒ\" loading=\"lazy\" src=\"/images/me.jpg\"\u003e\u003c/p\u003e\n\u003cp\u003eHiï¼Œä½œè€…æ¥è‡ªé‡åº†å¤§å­¦è½¯ä»¶å­¦é™¢æ•°æ®ç§‘å­¦ä¸å¤§æ•°æ®æŠ€æœ¯ä¸“ä¸šã€‚æ˜¯ä¸€åæ¥è‡ªæ¾³é—¨çš„æ¸¯æ¾³å°å­¦ç”Ÿã€‚\u003c/p\u003e\n\u003cp\u003eå†™åšå®¢çš„åˆè¡·æ˜¯ï¼š\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eè®°å½•è‡ªå·±è¸©è¿‡çš„å‘ï¼Œåˆ†äº«è‡ªå·±è§£å†³é—®é¢˜çš„æ€è·¯\u003c/li\u003e\n\u003cli\u003eè®°å½•æ¸¯æ¾³å°åœ¨å†…åœ°æ±‚å­¦çš„æ•…äº‹\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eå¦‚æœä½ åœ¨æˆ‘çš„åšå®¢ä¸­å‘ç°äº†é”™è¯¯ï¼Œæˆ–è€…æœ‰æ›´å¥½çš„å»ºè®®ï¼Œæ¬¢è¿éšæ—¶è”ç³»æˆ‘ï¼Œæˆ‘ä¼šè®¤çœŸå¯¹å¾…æ¯ä¸€ä¸ªåé¦ˆã€‚\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"è”ç³»æˆ‘\"\u003eè”ç³»æˆ‘\u003c/h2\u003e\n\u003cp\u003eå¦‚æœä½ å¯¹æˆ‘çš„åšå®¢å†…å®¹æ„Ÿå…´è¶£ï¼Œæˆ–è€…æœ‰ä»»ä½•é—®é¢˜å’Œå»ºè®®ï¼Œæ¬¢è¿é€šè¿‡ä»¥ä¸‹æ–¹å¼äº¤æµï¼š\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eå¾®ä¿¡/QQï¼š\u003ccode\u003e1363180320\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003eç”µå­é‚®ä»¶ï¼š\u003ccode\u003e1363180320@qq.com\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eæœŸå¾…ä¸ä½ çš„äº¤æµå’Œåˆä½œï¼\u003c/p\u003e\n\u003chr\u003e","title":"å…³äºä½œè€…"},{"content":"è¿™æ˜¯ä¸€ç¯‡ä»‹ç» Hugo åšå®¢çš„æ–‡ç« ã€‚åœ¨è¿™é‡Œæˆ‘ä»¬ä¼šä»‹ç»å¦‚ä½•å®‰è£…å’Œä½¿ç”¨ Hugoã€‚\nä¸€ã€å®‰è£… Hugo é¦–å…ˆï¼Œä½¿ç”¨ winget åœ¨ Windows ä¸Šå®‰è£… Hugoï¼š\nwinget install Hugo.Hugo.Extended å®‰è£…å®Œæˆåï¼ŒéªŒè¯æ˜¯å¦æˆåŠŸå®‰è£… Hugoï¼š\nhugo version å¦‚æœå‘½ä»¤è¡Œä¸­æ˜¾ç¤ºç‰ˆæœ¬ä¿¡æ¯ï¼Œè¯´æ˜å®‰è£…æˆåŠŸã€‚\näºŒã€åˆ›å»º Hugo ç½‘ç«™ æ¥ä¸‹æ¥ï¼Œåˆ›å»ºä¸€ä¸ªæ–°çš„ Hugo ç½‘ç«™ï¼š\nhugo new site my-blog è¿›å…¥ç«™ç‚¹ç›®å½•ï¼š\ncd my-blog ä¸‰ã€å®‰è£…ä¸»é¢˜ è®¿é—® Hugo Themes é€‰æ‹©å–œæ¬¢çš„ä¸»é¢˜ï¼Œæˆ–è€…ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ç›´æ¥å®‰è£… ananke ä¸»é¢˜ï¼š\ngit submodule add https://github.com/theNewDynamic/gohugo-theme-ananke.git themes/ananke ç„¶åï¼Œåœ¨ config.toml æ–‡ä»¶ä¸­è®¾ç½®ä¸»é¢˜ï¼š\ntheme = \u0026#34;ananke\u0026#34; å››ã€åˆ›å»ºæ–‡ç«  æ‚¨å¯ä»¥é€šè¿‡ä»¥ä¸‹å‘½ä»¤åˆ›å»ºä¸€ç¯‡æ–°çš„æ–‡ç« ï¼š\nhugo new posts/my-first-post.md åœ¨ content/posts/my-first-post.md æ–‡ä»¶ä¸­ï¼Œä½¿ç”¨ Markdown ç¼–è¾‘æ‚¨çš„æ–‡ç« å†…å®¹ã€‚\näº”ã€é¢„è§ˆæœ¬åœ°ç«™ç‚¹ é€šè¿‡å¯åŠ¨æœ¬åœ°æœåŠ¡å™¨ï¼Œæ‚¨å¯ä»¥åœ¨æµè§ˆå™¨ä¸­æŸ¥çœ‹ç«™ç‚¹æ•ˆæœï¼š\nhugo server -D åœ¨æµè§ˆå™¨ä¸­è®¿é—® http://localhost:1313/ è¿›è¡Œé¢„è§ˆã€‚\nå…­ã€éƒ¨ç½²åˆ° GitHub Pages 1. åˆ›å»º GitHub ä»“åº“ åœ¨ GitHub ä¸Šåˆ›å»ºä¸€ä¸ªæ–°çš„ä»“åº“ï¼Œå¹¶å‘½åä¸º username.github.ioï¼Œè¿™æ˜¯ GitHub Pages çš„æ ‡å‡†ä»“åº“å‘½åæ–¹å¼ã€‚\n2. åˆå§‹åŒ– Git ä»“åº“ åœ¨ç«™ç‚¹æ ¹ç›®å½•ä¸‹ï¼Œåˆå§‹åŒ– Git ä»“åº“å¹¶æ·»åŠ è¿œç¨‹ä»“åº“ï¼š\ngit init git remote add origin https://github.com/username/username.github.io.git 3. æ·»åŠ å¹¶æäº¤æ–‡ä»¶ æ·»åŠ æ‰€æœ‰æ–‡ä»¶å¹¶æäº¤ï¼š\ngit add . git commit -m \u0026#34;Initial commit\u0026#34; 4. æ¨é€åˆ° GitHub å°†æœ¬åœ°ä»“åº“æ¨é€åˆ° GitHubï¼š\ngit push -u origin master 5. å¯ç”¨ GitHub Pages åœ¨ GitHub ä»“åº“çš„è®¾ç½®ä¸­ï¼Œæ‰¾åˆ° GitHub Pages éƒ¨åˆ†ï¼Œé€‰æ‹© master æˆ– gh-pages åˆ†æ”¯ä½œä¸ºå‘å¸ƒæºã€‚\nä¸ƒã€è‡ªåŠ¨åŒ–éƒ¨ç½² ä¸ºäº†å®ç°è‡ªåŠ¨åŒ–éƒ¨ç½²ï¼Œä½¿ç”¨ GitHub Actionsã€‚ä»¥ä¸‹æ˜¯ä¸€ä¸ªç®€å•çš„å·¥ä½œæµç¤ºä¾‹ï¼š\nname: Deploy Hugo site to GitHub Pages on: push: branches: - master workflow_dispatch: permissions: contents: read pages: write id-token: write jobs: build: runs-on: ubuntu-latest steps: - uses: actions/checkout@v4 - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: \u0026#39;latest\u0026#39; extended: true - name: Build run: hugo --minify - name: Upload artifact uses: actions/upload-pages-artifact@v3 with: path: ./public deploy: needs: build runs-on: ubuntu-latest environment: name: github-pages url: ${{ steps.deployment.outputs.page_url }} steps: - name: Deploy to GitHub Pages id: deployment uses: actions/deploy-pages@v4 å°†æ­¤æ–‡ä»¶ä¿å­˜ä¸º .github/workflows/deploy.ymlï¼Œå¹¶æ¨é€åˆ° GitHub ä»“åº“ã€‚æ¯æ¬¡æ¨é€åˆ° master åˆ†æ”¯æ—¶ï¼ŒGitHub Actions å°†è‡ªåŠ¨æ„å»ºå¹¶éƒ¨ç½²åšå®¢ã€‚\n","permalink":"https://codeofwhite.github.io/posts/%E9%83%A8%E7%BD%B2%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2hugo-+-github-pages/","summary":"\u003cp\u003eè¿™æ˜¯ä¸€ç¯‡ä»‹ç» Hugo åšå®¢çš„æ–‡ç« ã€‚åœ¨è¿™é‡Œæˆ‘ä»¬ä¼šä»‹ç»å¦‚ä½•å®‰è£…å’Œä½¿ç”¨ Hugoã€‚\u003c/p\u003e","title":"éƒ¨ç½²ä¸ªäººåšå®¢ï¼šHugo + GitHub Pages"},{"content":"LeNet( (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1)) (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1)) (fc1): Linear(in_features=400, out_features=120, bias=True) (fc2): Linear(in_features=120, out_features=84, bias=True) (fc3): Linear(in_features=84, out_features=10, bias=True) ) åœ¨pytorché‡Œé¢, pruneé€šè¿‡å¯¹æƒé‡è¿›è¡Œæ©ç æ¥å®Œæˆ. è¿™ä¸ªå¦‚ä½•ç†è§£?\né¦–å…ˆ, æˆ‘ä»¬æ‰“å°ä¸€ä¸‹åŸå§‹çš„conv1çš„æƒé‡çœ‹çœ‹:\nmodule = model.conv1 print(list(module.named_modules())) print(list(module.named_buffers())) print(list(module.named_parameters())) è¿™é‡Œåˆ—ä¸¾äº†åé¢å¯èƒ½ä¼šç”¨åˆ°ä¸‰ä¸ªæ–¹æ³•, è¿™ä¸ªå¯ä»¥æŸ¥çœ‹å½“å‰çš„moduleåˆ°åº•æ˜¯ä¸€ä¸ªå•¥æƒ…å†µã€‚\nç€é‡è§‚å¯ŸÂ named_parametersÂ å› ä¸ºå‚æ•°éƒ½ä¿å­˜åœ¨è¿™é‡Œ, æ‰“å°å®Œäº†ä¹‹åå¯ä»¥çœ‹åˆ°:\n[(\u0026#39;weight\u0026#39;, Parameter containing: tensor([[[[-0.2312, 0.2133, -0.1313], [-0.2980, -0.1838, -0.2902], [-0.3006, 0.1338, -0.0980]]], [[[-0.1239, 0.1060, 0.3271], [-0.0301, -0.0245, 0.0493], [-0.0160, 0.0397, -0.1242]]]], device=\u0026#39;cuda:0\u0026#39;, requires_grad=True)), (\u0026#39;bias\u0026#39;, Parameter containing: tensor([-0.2593, -0.0520, 0.0303, 0.0382, -0.0468, -0.1053], device=\u0026#39;cuda:0\u0026#39;, requires_grad=True))] å®ƒæœ‰ä¸€ä¸ªweightå’Œä¸€ä¸ªbias, è¿™æ²¡é”™, åˆä¹å¸¸ç†. æˆ‘ä»¬ç”šè‡³å¯ä»¥çœ‹çœ‹weightsçš„å°ºå¯¸æ˜¯å¤šå°‘.\nfor a in module.named_parameters(): print(a[1].shape) è¾“å‡º:\ntorch.Size([6, 1, 3, 3]) torch.Size([6]) è¿™ä¸ªå…¶å®å°±æ˜¯å·ç§¯çš„ç»´åº¦äº†, 6æŒ‡çš„æ˜¯channel, 1å€¼å¾—è¿˜æ˜¯stride, 3æŒ‡çš„æ˜¯kernel size. ç„¶åé‡ç‚¹æ¥äº†, è¦å¼€å§‹åšpruneäº†, åœ¨pytorché‡Œé¢æ“ä½œä¹Ÿå¾ˆç®€å•, åªéœ€è¦ä¸€è¡Œä»£ç :\nimport torch.nn.utils.prune as prune â€‹ prune.random_unstructured(module, name=\u0026#39;weight\u0026#39;, amount=0.3) â€‹ è¿™ä¸ªå¯ä»¥ä»ä¼—å¤šçš„å‰ªææ–¹æ³•ä¸­, é€‰æ‹©ä¸€ä¸ªå¾ˆå¥½çš„æ‰‹æ®µæ¥å®ŒæˆåŒæ ·çš„ç›®çš„. ç„¶åæˆ‘ä»¬å†æ‰“å°ä¸€ä¸‹named_parameters:\n[(\u0026#39;bias\u0026#39;, Parameter containing: tensor([-0.2281, 0.3085, 0.0937, -0.0540, 0.3295, 0.1107], device=\u0026#39;cuda:0\u0026#39;, requires_grad=True)), (\u0026#39;weight_orig\u0026#39;, Parameter containing: tensor([[[[ 0.1934, -0.0172, -0.1957], [ 0.1655, 0.1669, -0.2448], [-0.2250, -0.0963, -0.0195]]], â€‹ [[[-0.3154, 0.1868, 0.0103], [-0.2245, 0.1548, 0.2567], [ 0.0713, 0.1262, 0.1547]]]], device=\u0026#39;cuda:0\u0026#39;, requires_grad=True))] å”¯ä¸€çš„å˜åŒ–å°±æ˜¯Â weightsÂ å˜æˆäº†Â weights_orig, pruneä¹‹åé€šè¿‡æ©ç çš„æ–¹å¼å­˜æ”¾åœ¨äº†Â named_buffersé‡Œé¢:\nprint(list(module.named_buffers())) å¯ä»¥çœ‹åˆ°:\n[(\u0026#39;weight_mask\u0026#39;, tensor([[[[1., 1., 1.], [0., 1., 0.], [0., 1., 1.]]], [[[0., 1., 0.], [0., 0., 1.], [0., 0., 1.]]]], device=\u0026#39;cuda:0\u0026#39;))] é‚£ä¹ˆé—®é¢˜æ¥äº†, åªæ˜¯æŠŠæƒé‡è¿›è¡Œäº†æ©ç , é‚£ä¹ˆæˆ‘è¦çŸ¥é“ä½ å‰ªæ‰äº†å“ªå‡ ä¸ªchannelæ€ä¹ˆåŠ? è€Œä¸”ä½ è¿™ä¸ªæ˜¯å‰ªçš„æƒé‡, ç»“æ„å‘¢? æˆ‘æ€ä¹ˆæŠŠè¿™ä¸ªç»“æ„æ‰¾å‡ºæ¥??\næ‰€ä»¥è¯´è¿™åªæ˜¯ç¬¬ä¸€æ­¥, æ¥ä¸‹æ¥æˆ‘ä»¬æ¥çœ‹çœ‹ç»“æ„åŒ–ä¿®å‰ª. ==ç»“æ„åŒ–ä¿®å‰ªè®²é“ç†ä½ å¯ä»¥çŸ¥é“ä½ ä¿®å‰ªäº†å“ªäº›ç»“æ„==.\nä¸€ä¸ªæ¯”è¾ƒå¥½çš„ç»“æ„åŒ–ä¿®å»ºçš„ä¾‹å­æ˜¯é€šè¿‡æ²¿ç€Tensorçš„æŸä¸ªç»´åº¦è¿›è¡Œè£å‰ª, è¿™æ ·ä½ å¯ä»¥ç›´æ¥çœ‹åˆ°ç»´åº¦çš„å˜åŒ–.\nç°åœ¨å¼€å§‹ä¿®å‰ªæ¨¡å—, æ¯”å¦‚ä¸Šé¢çš„LeNetçš„conv1å±‚, é¦–å…ˆæˆ‘ä»¬å¯ä»¥ä»pruneå±‚é‡Œé¢æ‹¿ä¸€ä¸ªæˆ‘ä»¬å–œæ¬¢çš„æŠ€æœ¯, æ¯”å¦‚åŸºäºÂ lnèŒƒæ•°Â çš„è¯„åˆ¤æ ‡å‡†æ¥è¿›è¡Œç»“æ„è¯çš„è£å‰ª.\nprune.ln_structured(module, name=\u0026#39;weight\u0026#39;, amount=0.5, n=2, dim=0) è¿™ä¸ªæ“ä½œä¹‹å, æˆ‘ä»¬å¾—åˆ°çš„å°†æ˜¯ä¸€ä¸ªæ–°çš„æƒé‡, å’Œä¸Šé¢çš„éç»“æ„åŒ–çš„ä¸åŒçš„åœ°æ–¹åœ¨äº, è¿™é‡Œæ˜¯æ•´ä¸ªçŸ©é˜µçš„ä¸€è¡Œä¸ºé›¶, ä¸Šé¢æˆ‘ä»¬ç”¨çš„dim=0, é‚£ä¹ˆå°±æ˜¯channelè¿™ä¸€ä¸ªç»´åº¦, ä¼šæœ‰50%ä¸ºé›¶.\n","permalink":"https://codeofwhite.github.io/posts/llm/pruning-%E4%BE%8B%E5%AD%90/","summary":"\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-text\" data-lang=\"text\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eLeNet(\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  (fc1): Linear(in_features=400, out_features=120, bias=True)\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  (fc2): Linear(in_features=120, out_features=84, bias=True)\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  (fc3): Linear(in_features=84, out_features=10, bias=True)\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eåœ¨pytorché‡Œé¢, pruneé€šè¿‡å¯¹æƒé‡è¿›è¡Œæ©ç æ¥å®Œæˆ. è¿™ä¸ªå¦‚ä½•ç†è§£?\u003c/p\u003e\n\u003cp\u003eé¦–å…ˆ, æˆ‘ä»¬æ‰“å°ä¸€ä¸‹åŸå§‹çš„conv1çš„æƒé‡çœ‹çœ‹:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-text\" data-lang=\"text\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003emodule = model.conv1\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eprint(list(module.named_modules()))\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eprint(list(module.named_buffers()))\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eprint(list(module.named_parameters()))\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eè¿™é‡Œåˆ—ä¸¾äº†åé¢å¯èƒ½ä¼šç”¨åˆ°ä¸‰ä¸ªæ–¹æ³•, è¿™ä¸ªå¯ä»¥æŸ¥çœ‹å½“å‰çš„moduleåˆ°åº•æ˜¯ä¸€ä¸ªå•¥æƒ…å†µã€‚\u003c/p\u003e\n\u003cp\u003eç€é‡è§‚å¯ŸÂ \u003ccode\u003enamed_parameters\u003c/code\u003eÂ å› ä¸ºå‚æ•°éƒ½ä¿å­˜åœ¨è¿™é‡Œ, æ‰“å°å®Œäº†ä¹‹åå¯ä»¥çœ‹åˆ°:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-text\" data-lang=\"text\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e[(\u0026#39;weight\u0026#39;, Parameter containing:\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003etensor([[[[-0.2312,  0.2133, -0.1313],\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e          [-0.2980, -0.1838, -0.2902],\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e          [-0.3006,  0.1338, -0.0980]]],\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e        [[[-0.1239,  0.1060,  0.3271],\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e          [-0.0301, -0.0245,  0.0493],\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e          [-0.0160,  0.0397, -0.1242]]]], device=\u0026#39;cuda:0\u0026#39;, requires_grad=True)), (\u0026#39;bias\u0026#39;, Parameter containing:\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003etensor([-0.2593, -0.0520,  0.0303,  0.0382, -0.0468, -0.1053], device=\u0026#39;cuda:0\u0026#39;,\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e       requires_grad=True))]\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eå®ƒæœ‰ä¸€ä¸ªweightå’Œä¸€ä¸ªbias, è¿™æ²¡é”™, åˆä¹å¸¸ç†. æˆ‘ä»¬ç”šè‡³å¯ä»¥çœ‹çœ‹weightsçš„å°ºå¯¸æ˜¯å¤šå°‘.\u003c/p\u003e","title":"Pruning ä¾‹å­"},{"content":"å¦‚ä½•å°†è¿™äº›æ¨¡å‹ä¿å­˜ä¸‹æ¥. æ¢å¥è¯è¯´, ä½ å‰ªæå®Œäº†ä¹‹å, ä½ å¾—åˆ°äº†ä¸€ä¸ªmaskçš„æ©ç , ä¸ç®¡æ˜¯ç»“æ„åŒ–è¿˜æ˜¯éç»“æ„åŒ–, è¿™ä¸ªæ–°çš„æ¨¡å‹ä½ è¦æ€ä¹ˆæ ·æ‰èƒ½å¯¼å‡ºå‘¢? è¯•æƒ³ä¸€ä¸‹, å¦‚æœåªæ˜¯å¾—åˆ°è¿™ä¹ˆä¸€ä¸ªæ©ç , ä½ åœ¨æ¨ç†çš„æ—¶å€™, åªæ˜¯è¿™ä¸€éƒ¨åˆ†æƒé‡ä¸ºé›¶è€Œå·², ä½ æ¨ç†çš„é•¿å®½é«˜å•¥çš„éƒ½ä¹ˆæœ‰æ”¹å˜, so, é€Ÿåº¦ä¼šå˜å¾—æ›´å¿«å—?\nè¿™ä½è€å“¥å‘ç°, ä»–å°è¯•ä¸ç®¡æ˜¯ç»“æ„åŒ–å‰ªæè¿˜æ˜¯éç»“æ„åŒ–å‰ªæ, é€Ÿåº¦å’Œæ¨¡å‹çš„å¤§å°éƒ½æ²¡æœ‰å˜åŒ–. ç„¶åå¦å¤–ä¸€ä¸ªè€å“¥å°±å‘Šè¯‰ä»–çœŸåƒäº†:\né‡è¦çš„æ˜¯è¦äº†è§£éç»“æ„åŒ–ä¿®å‰ªå’Œç»“æ„åŒ–ä¿®å‰ªä¹‹é—´çš„åŒºåˆ«ã€‚\nç»“æ„åŒ–ä¿®å‰ªï¼šé€šè¿‡åˆ é™¤å¼ é‡çš„æ•´è¡Œ/åˆ—æ¥å‡å°é‡é‡å¼ é‡çš„å°ºå¯¸ã€‚è¿™è½¬åŒ–ä¸ºå»é™¤ç¥ç»å…ƒåŠå…¶æ‰€æœ‰ä¼ å…¥å’Œä¼ å‡ºè¿æ¥ï¼ˆåœ¨å¯†é›†å±‚ä¸­ï¼‰æˆ–æ•´ä¸ªå·ç§¯è¿‡æ»¤å™¨ï¼ˆåœ¨å·ç§¯å±‚ä¸­ï¼‰ã€‚\néç»“æ„åŒ–ä¿®å‰ªï¼šå•ä¸ªæƒé‡å¯ä»¥â€œå»é™¤â€ï¼ˆå½’é›¶ï¼‰ï¼Œè€Œä¸å—æœ€ç»ˆå¼ é‡å½¢çŠ¶çš„é™åˆ¶ã€‚è¿™æ„å‘³ç€åˆ é™¤ç¥ç»å…ƒä¹‹é—´çš„å•ä¸ªè¿æ¥ï¼ˆåœ¨å¯†é›†å±‚ä¸­ï¼‰æˆ–åˆ é™¤å·ç§¯è¿‡æ»¤å™¨çš„å•ä¸ªæƒé‡ï¼ˆåœ¨å·ç§¯å±‚ä¸­ï¼‰ã€‚\nè¯·æ³¨æ„ï¼Œç”Ÿæˆçš„é‡é‡å¼ é‡å¯ä»¥ç¨€ç–ï¼Œä½†ä¿æŒå…¶åŸå§‹å½¢çŠ¶ã€‚ç›®å‰ï¼Œtorch.nn.utils.pruneä»…æ”¯æŒéç»“æ„åŒ–ä¿®å‰ªï¼Œè¿™å‡ ä¹æ— æ³•å¸®åŠ©é™ä½æ¨ç†æˆæœ¬ï¼Œå› ä¸º==GPUå¹¶æœªé’ˆå¯¹ç¨€ç–çŸ©é˜µä¹˜æ³•è¿›è¡Œä¼˜åŒ–==ã€‚è™½ç„¶æ‚¨å¯èƒ½å¸Œæœ›å‡å°æƒé‡å¼ é‡çš„å°ºå¯¸ä»¥å‡å°‘æµ®ç‚¹è¿ç®—çš„æ•°é‡ï¼Œä½†éç»“æ„åŒ–ä¿®å‰ªä¼šäº§ç”Ÿå¸¦æœ‰è®¸å¤šé›¶çš„æƒé‡å¼ é‡ï¼Œä½†ä¸ä¼šè‡ªåŠ¨å‡å°æ­¤ç±»å¼ é‡çš„å¤§å°ã€‚ä»…å½“å»é™¤è®¸å¤šè´Ÿæ‹…æ—¶ï¼Œéç»“æ„åŒ–ä¿®å‰ªæ‰èƒ½å¸®åŠ©æé«˜æ€§èƒ½ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ‚¨å¯ä»¥ä¾é PyTorchç¨€ç–æ“ä½œï¼Œä¹Ÿå¯ä»¥å°è¯•æŸ¥æ‰¾åŒ…å«å…¨é›¶çš„è¡Œ/åˆ—ï¼Œå› æ­¤å¯ä»¥å°†å…¶åˆ é™¤ã€‚ç›¸åï¼Œå¦‚æœè¦ç ”ç©¶ç»“æ„åŒ–ä¿®å‰ªï¼Œå¯ä»¥çœ‹ä¸€ä¸‹TorchPrunerï¼Œè¿™æ˜¯æˆ‘ä¸ºç ”ç©¶ç›®çš„è€Œè‡ªè¡Œå¼€å‘çš„ä¸€ä¸ªåº“ï¼Œå®ƒæä¾›äº†å®ç”¨ç¨‹åºæ¥æŸ¥æ‰¾æœ€ä¸é‡è¦çš„ç¥ç»å…ƒå¹¶ç›¸åº”åœ°å¯¹é‡é‡å¼ é‡è¿›è¡Œåˆ‡ç‰‡ã€‚\næ‰€ä»¥, è¿™ä¸ªéƒ¨åˆ†æˆ‘ä»¬ä¹Ÿåº”è¯¥çŸ¥é“, äº‹å®ä¸Špytorchçš„pruneé‡Œé¢åšçš„äº‹æƒ…, åªæ˜¯æ‰¾åˆ°å“ªäº›å±‚æ˜¯å¯ä»¥ç½®é›¶çš„è€Œå·², è¯·æ³¨æ„, è¿™é‡Œçš„å±‚æŒ‡çš„ä¸æ˜¯æŸä¸ªlayer, è€Œæ˜¯ä¸€ä¸ªå·ç§¯å±‚çŸ©é˜µé‡Œé¢çš„æŸä¸€æ•´è¡Œæˆ–è€…æŸä¸€æ•´åˆ—.\näº‹å®ä¸Špytorchçš„pruneé‡Œé¢åšçš„äº‹æƒ…, åªæ˜¯æ‰¾åˆ°å“ªäº›å±‚æ˜¯å¯ä»¥ç½®é›¶çš„è€Œå·², è¯·æ³¨æ„, è¿™é‡Œçš„å±‚æŒ‡çš„ä¸æ˜¯æŸä¸ªlayer, è€Œæ˜¯ä¸€ä¸ªå·ç§¯å±‚çŸ©é˜µé‡Œé¢çš„æŸä¸€æ•´è¡Œæˆ–è€…æŸä¸€æ•´åˆ—.\né‚£ä¹ˆé—®é¢˜æ¥äº†, å¬èµ·æ¥æˆ‘ä»¬è¦ä¿å­˜æ¨¡å‹, è¦å¾—åˆ°é€Ÿåº¦åŠ å¿«, æ¨¡å‹å˜å°çš„æ¨¡å‹, è¿˜éœ€è¦å†æ¯ä¸€ä¸ªpruneçš„å±‚é‡Œé¢æ‰¾åˆ°æŸä¸€è¢«å…¨ç½®é›¶çš„é“¾æ¥, ç„¶åå†æ‹¿æ¥åšæ¨ç†.\nå¯æ˜¯è¿™ä¸ªæ€ä¹ˆå¬èµ·æ¥è¿™ä¹ˆå¤æ‚å‘¢? äº‹å®ä¸Šåœ¨å®é™…åº”ç”¨ä¸­åº”è¯¥æ€ä¹ˆåšå‘¢? è¿™å°±å¼•å…¥äº†ä¸‹ä¸€ç¯‡æ•™ç¨‹: ä½¿ç”¨Distillerçš„å·¥ä¸šåº”ç”¨æ¨¡å‹å‰ªææ•™ç¨‹.\n","permalink":"https://codeofwhite.github.io/posts/llm/pruning-%E5%90%8E%E7%9A%84%E5%B7%A5%E4%BD%9C/","summary":"\u003cp\u003eå¦‚ä½•å°†è¿™äº›æ¨¡å‹ä¿å­˜ä¸‹æ¥. æ¢å¥è¯è¯´, ä½ å‰ªæå®Œäº†ä¹‹å, ä½ å¾—åˆ°äº†ä¸€ä¸ªmaskçš„æ©ç , ä¸ç®¡æ˜¯ç»“æ„åŒ–è¿˜æ˜¯éç»“æ„åŒ–, è¿™ä¸ªæ–°çš„æ¨¡å‹ä½ è¦æ€ä¹ˆæ ·æ‰èƒ½å¯¼å‡ºå‘¢? è¯•æƒ³ä¸€ä¸‹, å¦‚æœåªæ˜¯å¾—åˆ°è¿™ä¹ˆä¸€ä¸ªæ©ç , ä½ åœ¨æ¨ç†çš„æ—¶å€™, åªæ˜¯è¿™ä¸€éƒ¨åˆ†æƒé‡ä¸ºé›¶è€Œå·², ä½ æ¨ç†çš„é•¿å®½é«˜å•¥çš„éƒ½ä¹ˆæœ‰æ”¹å˜, so, é€Ÿåº¦ä¼šå˜å¾—æ›´å¿«å—?\u003c/p\u003e\n\u003cp\u003eè¿™ä½è€å“¥å‘ç°, ä»–å°è¯•ä¸ç®¡æ˜¯ç»“æ„åŒ–å‰ªæè¿˜æ˜¯éç»“æ„åŒ–å‰ªæ, é€Ÿåº¦å’Œæ¨¡å‹çš„å¤§å°éƒ½æ²¡æœ‰å˜åŒ–. ç„¶åå¦å¤–ä¸€ä¸ªè€å“¥å°±å‘Šè¯‰ä»–çœŸåƒäº†:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eé‡è¦çš„æ˜¯è¦äº†è§£éç»“æ„åŒ–ä¿®å‰ªå’Œç»“æ„åŒ–ä¿®å‰ªä¹‹é—´çš„åŒºåˆ«ã€‚\u003cbr\u003e\n\u003cstrong\u003eç»“æ„åŒ–ä¿®å‰ª\u003c/strong\u003eï¼šé€šè¿‡åˆ é™¤å¼ é‡çš„æ•´è¡Œ/åˆ—æ¥å‡å°é‡é‡å¼ é‡çš„å°ºå¯¸ã€‚è¿™è½¬åŒ–ä¸ºå»é™¤ç¥ç»å…ƒåŠå…¶æ‰€æœ‰ä¼ å…¥å’Œä¼ å‡ºè¿æ¥ï¼ˆåœ¨å¯†é›†å±‚ä¸­ï¼‰æˆ–æ•´ä¸ªå·ç§¯è¿‡æ»¤å™¨ï¼ˆåœ¨å·ç§¯å±‚ä¸­ï¼‰ã€‚\u003cbr\u003e\n\u003cstrong\u003eéç»“æ„åŒ–ä¿®å‰ª\u003c/strong\u003eï¼šå•ä¸ªæƒé‡å¯ä»¥â€œå»é™¤â€ï¼ˆå½’é›¶ï¼‰ï¼Œè€Œä¸å—æœ€ç»ˆå¼ é‡å½¢çŠ¶çš„é™åˆ¶ã€‚è¿™æ„å‘³ç€åˆ é™¤ç¥ç»å…ƒä¹‹é—´çš„å•ä¸ªè¿æ¥ï¼ˆåœ¨å¯†é›†å±‚ä¸­ï¼‰æˆ–åˆ é™¤å·ç§¯è¿‡æ»¤å™¨çš„å•ä¸ªæƒé‡ï¼ˆåœ¨å·ç§¯å±‚ä¸­ï¼‰ã€‚\u003cbr\u003e\nè¯·æ³¨æ„ï¼Œç”Ÿæˆçš„é‡é‡å¼ é‡å¯ä»¥ç¨€ç–ï¼Œä½†ä¿æŒå…¶åŸå§‹å½¢çŠ¶ã€‚ç›®å‰ï¼Œtorch.nn.utils.pruneä»…æ”¯æŒéç»“æ„åŒ–ä¿®å‰ªï¼Œè¿™å‡ ä¹æ— æ³•å¸®åŠ©é™ä½æ¨ç†æˆæœ¬ï¼Œå› ä¸º==GPUå¹¶æœªé’ˆå¯¹ç¨€ç–çŸ©é˜µä¹˜æ³•è¿›è¡Œä¼˜åŒ–==ã€‚è™½ç„¶æ‚¨å¯èƒ½å¸Œæœ›å‡å°æƒé‡å¼ é‡çš„å°ºå¯¸ä»¥å‡å°‘æµ®ç‚¹è¿ç®—çš„æ•°é‡ï¼Œä½†éç»“æ„åŒ–ä¿®å‰ªä¼šäº§ç”Ÿå¸¦æœ‰è®¸å¤šé›¶çš„æƒé‡å¼ é‡ï¼Œä½†ä¸ä¼šè‡ªåŠ¨å‡å°æ­¤ç±»å¼ é‡çš„å¤§å°ã€‚ä»…å½“å»é™¤è®¸å¤šè´Ÿæ‹…æ—¶ï¼Œéç»“æ„åŒ–ä¿®å‰ªæ‰èƒ½å¸®åŠ©æé«˜æ€§èƒ½ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ‚¨å¯ä»¥ä¾é PyTorchç¨€ç–æ“ä½œï¼Œä¹Ÿå¯ä»¥å°è¯•æŸ¥æ‰¾åŒ…å«å…¨é›¶çš„è¡Œ/åˆ—ï¼Œå› æ­¤å¯ä»¥å°†å…¶åˆ é™¤ã€‚ç›¸åï¼Œå¦‚æœè¦ç ”ç©¶ç»“æ„åŒ–ä¿®å‰ªï¼Œå¯ä»¥çœ‹ä¸€ä¸‹TorchPrunerï¼Œè¿™æ˜¯æˆ‘ä¸ºç ”ç©¶ç›®çš„è€Œè‡ªè¡Œå¼€å‘çš„ä¸€ä¸ªåº“ï¼Œå®ƒæä¾›äº†å®ç”¨ç¨‹åºæ¥æŸ¥æ‰¾æœ€ä¸é‡è¦çš„ç¥ç»å…ƒå¹¶ç›¸åº”åœ°å¯¹é‡é‡å¼ é‡è¿›è¡Œåˆ‡ç‰‡ã€‚\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eæ‰€ä»¥, è¿™ä¸ªéƒ¨åˆ†æˆ‘ä»¬ä¹Ÿåº”è¯¥çŸ¥é“, äº‹å®ä¸Špytorchçš„pruneé‡Œé¢åšçš„äº‹æƒ…, åªæ˜¯æ‰¾åˆ°å“ªäº›å±‚æ˜¯å¯ä»¥ç½®é›¶çš„è€Œå·², è¯·æ³¨æ„, è¿™é‡Œçš„å±‚æŒ‡çš„ä¸æ˜¯æŸä¸ªlayer, è€Œæ˜¯ä¸€ä¸ªå·ç§¯å±‚çŸ©é˜µé‡Œé¢çš„æŸä¸€æ•´è¡Œæˆ–è€…æŸä¸€æ•´åˆ—.\u003c/p\u003e\n\u003cp\u003eäº‹å®ä¸Špytorchçš„pruneé‡Œé¢åšçš„äº‹æƒ…, åªæ˜¯æ‰¾åˆ°å“ªäº›å±‚æ˜¯å¯ä»¥ç½®é›¶çš„è€Œå·², è¯·æ³¨æ„, è¿™é‡Œçš„å±‚æŒ‡çš„ä¸æ˜¯æŸä¸ªlayer, è€Œæ˜¯ä¸€ä¸ªå·ç§¯å±‚çŸ©é˜µé‡Œé¢çš„æŸä¸€æ•´è¡Œæˆ–è€…æŸä¸€æ•´åˆ—.\u003c/p\u003e\n\u003cp\u003eé‚£ä¹ˆé—®é¢˜æ¥äº†, å¬èµ·æ¥æˆ‘ä»¬è¦ä¿å­˜æ¨¡å‹, è¦å¾—åˆ°é€Ÿåº¦åŠ å¿«, æ¨¡å‹å˜å°çš„æ¨¡å‹, è¿˜éœ€è¦å†æ¯ä¸€ä¸ªpruneçš„å±‚é‡Œé¢æ‰¾åˆ°æŸä¸€è¢«å…¨ç½®é›¶çš„é“¾æ¥, ç„¶åå†æ‹¿æ¥åšæ¨ç†.\u003c/p\u003e\n\u003cp\u003eå¯æ˜¯è¿™ä¸ªæ€ä¹ˆå¬èµ·æ¥è¿™ä¹ˆå¤æ‚å‘¢? äº‹å®ä¸Šåœ¨å®é™…åº”ç”¨ä¸­åº”è¯¥æ€ä¹ˆåšå‘¢?\nè¿™å°±å¼•å…¥äº†ä¸‹ä¸€ç¯‡æ•™ç¨‹: ä½¿ç”¨Distillerçš„å·¥ä¸šåº”ç”¨æ¨¡å‹å‰ªææ•™ç¨‹.\u003c/p\u003e","title":"Pruning åçš„å·¥ä½œ"},{"content":"ä¸ºä»€ä¹ˆéœ€è¦å‰ªæï¼Ÿ è¿‡å‚æ•°åŒ–ä¸»è¦æ˜¯æŒ‡åœ¨è®­ç»ƒé˜¶æ®µï¼Œåœ¨æ•°å­¦ä¸Šéœ€è¦è¿›è¡Œå¤§é‡çš„å¾®åˆ†æ±‚è§£ï¼Œå»æ•æŠ“æ•°æ®ä¸­çš„å¾®å°å˜åŒ–ä¿¡æ¯ï¼Œä¸€æ—¦å®Œæˆè¿­ä»£å¼çš„è®­ç»ƒä¹‹åï¼Œç½‘ç»œæ¨¡å‹æ¨ç†çš„æ—¶å€™å°±ä¸éœ€è¦è¿™ä¹ˆå¤šå‚æ•°ã€‚è€Œå‰ªæç®—æ³•æ­£æ˜¯åŸºäºè¿‡å‚æ•°åŒ–çš„ç†è®ºåŸºç¡€è€Œæå‡ºçš„ã€‚\næ ¸å¿ƒæ€æƒ³ï¼šå‡å°‘ç½‘ç»œæ¨¡å‹ä¸­å‚æ•°é‡å’Œè®¡ç®—é‡ï¼ŒåŒæ—¶å°½é‡ä¿è¯æ¨¡å‹çš„æ€§èƒ½ä¸å—å½±å“ã€‚ å‰ªæç®—æ³•åˆ†ç±» 1ï¼‰Drop Outï¼šéšæœºçš„å°†ä¸€äº›ç¥ç»å…ƒçš„è¾“å‡ºç½®é›¶ï¼Œç§°ä¹‹ä¸ºç¥ç»å…ƒå‰ªæã€‚ã€è¿™ä¸ªä¸€çœ¼çœ‹åˆ°å°±æ„Ÿè§‰ä¼šæœ‰é—®é¢˜ã€‘ 2ï¼‰Drop Connectï¼šéšæœºå°†éƒ¨åˆ†ç¥ç»å…ƒé—´çš„è¿æ¥Connectç½®é›¶ï¼Œä½¿å¾—æƒé‡è¿æ¥çŸ©é˜µå˜å¾—ç¨€ç–ã€‚ã€è¿™ä¸ªè¿˜å¯ä»¥ã€‘\nç»“æ„åŒ–å‰ªæ éç»“æ„åŒ–å‰ªæ 1)Â ç»†ç²’åº¦å‰ªæ(fine-grained)ï¼šå³å¯¹è¿æ¥æˆ–è€…ç¥ç»å…ƒè¿›è¡Œå‰ªæï¼Œæ˜¯ç²’åº¦æœ€å°çš„å‰ªæï¼Œä¸Šé¢Drop Outå’ŒDrop Connectéƒ½æ˜¯å±äºç»†ç²’åº¦å‰ªæã€‚ 2) å‘é‡å‰ªæ(vector-level)ï¼šå®ƒç›¸å¯¹äºç»†ç²’åº¦å‰ªæç²’åº¦ç¨å¤§ï¼Œå±äºå¯¹å·ç§¯æ ¸å†…éƒ¨(intra-kernel) çš„å‰ªæã€‚ 3) æ ¸å‰ªæ(kernel-level)ï¼šå³å»é™¤æŸä¸ªå·ç§¯æ ¸ï¼Œä¸¢å¼ƒå¯¹è¾“å…¥é€šé“ä¸­å¯¹åº”å·ç§¯æ ¸çš„è®¡ç®—ã€‚ 4) æ»¤æ³¢å™¨å‰ªæ(Filter-level)ï¼šå¯¹æ•´ä¸ªå·ç§¯æ ¸ç»„è¿›è¡Œå‰ªæï¼Œ==æ¨ç†è¿‡ç¨‹ä¸­è¾“å‡ºç‰¹å¾é€šé“æ•°ä¼šæ”¹å˜==ã€‚\nç»†ç²’åº¦å‰ªæã€å‘é‡å‰ªæã€æ ¸å‰ªæåœ¨å‚æ•°é‡ä¸æ¨¡å‹æ€§èƒ½ä¹‹é—´å–å¾—äº†ä¸€å®šçš„å¹³è¡¡ï¼Œä½†æ˜¯ç½‘ç»œæ¨¡å‹å•å±‚çš„ç¥ç»å…ƒä¹‹é—´çš„ç»„åˆç»“æ„å‘ç”Ÿäº†å˜åŒ–ï¼Œéœ€è¦ä¸“é—¨çš„ç®—æ³•æˆ–è€…ç¡¬ä»¶ç»“æ„æ¥æ”¯æŒç¨€ç–çš„è¿ç®—ï¼Œè¿™ç§å«åšéç»“æ„åŒ–å‰ªæï¼ˆUnstructured Pruningï¼‰ã€‚\nå…¶ä¸­ï¼Œéç»“æ„åŒ–å‰ªæèƒ½å¤Ÿå®ç°æ›´é«˜çš„å‹ç¼©ç‡ï¼ŒåŒæ—¶ä¿æŒè¾ƒé«˜çš„æ¨¡å‹æ€§èƒ½ï¼Œç„¶è€Œä¼šå¸¦æ¥ç½‘ç»œæ¨¡å‹ç¨€ç–åŒ–ï¼Œå…¶ç¨€ç–ç»“æ„å¯¹äºç¡¬ä»¶åŠ é€Ÿè®¡ç®—å¹¶ä¸å‹å¥½ï¼Œé™¤éåº•å±‚ç¡¬ä»¶å’Œè®¡ç®—åŠ é€Ÿåº“å¯¹ç¨€ç–è®¡ç®—æœ‰æ¯”è¾ƒå¥½çš„æ”¯æŒï¼Œå¦åˆ™å‰ªæåå¾ˆéš¾è·å¾—å®è´¨çš„æ€§èƒ½æå‡ã€‚\næ»¤æ³¢å™¨å‰ªæï¼ˆFilter-levelï¼‰ ä¸»è¦æ”¹å˜ç½‘ç»œä¸­çš„æ»¤æ³¢å™¨ç»„å’Œç‰¹å¾é€šé“æ•°ç›®ï¼Œæ‰€è·å¾—çš„æ¨¡å‹ä¸éœ€è¦ä¸“é—¨çš„ç®—æ³•å’Œç¡¬ä»¶å°±èƒ½å¤Ÿè¿è¡Œï¼Œè¢«ç§°ä¸ºç»“æ„åŒ–å‰ªæï¼ˆStructured Pruningï¼‰ã€‚ç»“æ„åŒ–å‰ªæåˆå¯è¿›ä¸€æ­¥ç»†åˆ†ï¼šå¯ä»¥æ˜¯channel-wiseï¼Œä¹Ÿå¯ä»¥æ˜¯filter-wiseï¼Œè¿˜å¯ä»¥æ˜¯åœ¨shape-wiseã€‚\nç»“æ„åŒ–å‰ªæä¸éç»“æ„åŒ–å‰ªææ°æ°ç›¸åï¼Œå¯ä»¥æ–¹ä¾¿æ”¹å˜ç½‘ç»œæ¨¡å‹çš„ç»“æ„ç‰¹å¾ï¼Œä»è€Œè¾¾åˆ°å‹ç¼©æ¨¡å‹çš„æ•ˆæœï¼Œä¾‹å¦‚çŸ¥è¯†è’¸é¦ä¸­çš„studentç½‘ç»œæ¨¡å‹ã€NASæœç´¢æˆ–è€…å¦‚VGG19å’ŒVGG16è¿™ç§è£å‰ªæ¨¡å‹ï¼Œä¹Ÿå¯ä»¥çœ‹åšå˜ç›¸çš„ç»“æ„åŒ–å‰ªæè¡Œä¸ºã€‚\nå‰ªæç®—æ³•æµç¨‹ è™½ç„¶å‰ªæç®—æ³•çš„åˆ†ç±»çœ‹ä¸Šå»å¾ˆå¤šï¼Œä½†æ˜¯æ ¸å¿ƒæ€æƒ³è¿˜æ˜¯å¯¹ç¥ç»ç½‘ç»œæ¨¡å‹è¿›è¡Œå‰ªæï¼Œç›®å‰å‰ªæç®—æ³•çš„æ€»ä½“æµç¨‹å¤§åŒå°å¼‚ï¼Œå¯ä»¥å½’ç»“ä¸ºä¸‰ç§ï¼šæ ‡å‡†å‰ªæã€åŸºäºå­æ¨¡å‹é‡‡æ ·çš„å‰ªæã€ä»¥åŠåŸºäºæœç´¢çš„å‰ªæï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚\næ ‡å‡†å‰ªæç®—æ³•æµç¨‹ æ ‡å‡†å‰ªææ˜¯ç›®å‰æœ€æµè¡Œçš„å‰ªææµç¨‹ï¼Œåœ¨Tensorflowã€Pytrochéƒ½æœ‰æ ‡å‡†çš„æ¥å£ã€‚ä¸»è¦åŒ…å«ä¸‰ä¸ªéƒ¨åˆ†ï¼šè®­ç»ƒã€å‰ªæã€ä»¥åŠå¾®è°ƒã€‚\n1ï¼‰è®­ç»ƒï¼šé¦–å…ˆæ˜¯å¯¹ç½‘ç»œæ¨¡å‹è¿›è¡Œè®­ç»ƒã€‚åœ¨å‰ªææµç¨‹ä¸­ï¼Œè®­ç»ƒéƒ¨åˆ†ä¸»è¦æŒ‡é¢„è®­ç»ƒï¼Œè®­ç»ƒçš„ç›®çš„æ˜¯ä¸ºå‰ªæç®—æ³•è·å¾—åœ¨ç‰¹å®šåŸºç¡€SOTAä»»åŠ¡ä¸Šè®­ç»ƒå¥½çš„åŸå§‹æ¨¡å‹ã€‚ 2ï¼‰å‰ªæï¼šåœ¨è¿™é‡Œé¢å¯ä»¥è¿›è¡Œå¦‚ç»†ç²’åº¦å‰ªæã€å‘é‡å‰ªæã€æ ¸å‰ªæã€æ»¤æ³¢å™¨å‰ªæç­‰å„ç§ä¸åŒçš„å‰ªæç®—æ³•ã€‚å…¶ä¸­å¾ˆé‡è¦çš„å°±ä¸€ç‚¹ï¼Œå°±æ˜¯åœ¨å‰ªæä¹‹åï¼Œ==å¯¹ç½‘ç»œæ¨¡å‹ç»“æ„è¿›è¡Œè¯„ä¼°==ã€‚ç¡®å®šä¸€ä¸ªéœ€è¦å‰ªæçš„å±‚ï¼Œè®¾å®šä¸€ä¸ªè£å‰ªé˜ˆå€¼æˆ–è€…æ¯”ä¾‹ã€‚å®ç°ä¸Šï¼Œé€šè¿‡ä¿®æ”¹ä»£ç åŠ å…¥ä¸€ä¸ªä¸å‚æ•°çŸ©é˜µå°ºå¯¸ä¸€è‡´çš„==MaskçŸ©é˜µ==ã€‚MaskçŸ©é˜µä¸­åªæœ‰0å’Œ1ï¼Œå®é™…ä¸Šæ˜¯ç”¨äºå¾®è°ƒç½‘ç»œã€‚ 3ï¼‰ å¾®è°ƒï¼šå¾®è°ƒæ˜¯æ¢å¤è¢«å‰ªææ“ä½œå½±å“çš„æ¨¡å‹è¡¨è¾¾èƒ½åŠ›çš„å¿…è¦æ­¥éª¤ã€‚ç»“æ„åŒ–æ¨¡å‹å‰ªæä¼šå¯¹åŸå§‹æ¨¡å‹ç»“æ„è¿›è¡Œè°ƒæ•´ï¼Œå› æ­¤å‰ªæåçš„æ¨¡å‹å‚æ•°è™½ç„¶ä¿ç•™äº†åŸå§‹çš„æ¨¡å‹å‚æ•°ï¼Œä½†æ˜¯==ç”±äºæ¨¡å‹ç»“æ„çš„æ”¹å˜ï¼Œå‰ªæåæ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›ä¼šå—åˆ°ä¸€å®šç¨‹åº¦çš„å½±å“==ã€‚å®ç°ä¸Šï¼Œå¾®è°ƒç½‘ç»œæ¨¡å‹ï¼Œå‚æ•°åœ¨è®¡ç®—çš„æ—¶å€™å…ˆä¹˜ä»¥è¯¥Maskï¼ŒMaskä¸º1çš„å‚æ•°å€¼å°†ç»§ç»­è®­ç»ƒé€šè¿‡BPè°ƒæ•´æ¢¯åº¦ï¼Œè€ŒMaskä¸º0çš„éƒ¨åˆ†å› ä¸ºè¾“å‡ºå§‹ç»ˆä¸º0åˆ™ä¸å¯¹åç»­éƒ¨åˆ†äº§ç”Ÿå½±å“ã€‚ 4ï¼‰å†å‰ªæï¼šå†å‰ªæè¿‡ç¨‹å°†å¾®è°ƒä¹‹åçš„ç½‘ç»œæ¨¡å‹å†é€åˆ°å‰ªææ¨¡å—ä¸­ï¼Œå†æ¬¡è¿›è¡Œæ¨¡å‹ç»“æ„è¯„ä¼°å’Œæ‰§è¡Œå‰ªæç®—æ³•ã€‚ç›®çš„æ˜¯ä½¿å¾—æ¯æ¬¡å‰ªæéƒ½åœ¨æ€§èƒ½æ›´ä¼˜çš„æ¨¡å‹ä¸Šé¢è¿›è¡Œï¼Œä¸æ–­è¿­ä»£å¼åœ°è¿›è¡Œä¼˜åŒ–å‰ªææ¨¡å‹ï¼Œç›´åˆ°æ¨¡å‹èƒ½å¤Ÿæ»¡è¶³å‰ªæç›®æ ‡éœ€æ±‚ã€‚\næœ€åè¾“å‡ºæ¨¡å‹å‚æ•°å‚¨å­˜çš„æ—¶å€™ï¼Œå› ä¸ºæœ‰==å¤§é‡çš„ç¨€ç–==ï¼Œæ‰€ä»¥å¯ä»¥é‡æ–°å®šä¹‰å‚¨å­˜çš„æ•°æ®ç»“æ„ï¼Œ ==ä»…å‚¨å­˜éé›¶å€¼ä»¥åŠå…¶çŸ©é˜µä½ç½®==ã€‚é‡æ–°è¯»å–æ¨¡å‹å‚æ•°çš„æ—¶å€™ï¼Œå°±å¯ä»¥è¿˜åŸçŸ©é˜µã€‚\nåŸºäºå­æ¨¡å‹é‡‡æ ·æµç¨‹ é™¤æ ‡å‡†å‰ªæä¹‹å¤–ï¼ŒåŸºäºå­æ¨¡å‹é‡‡æ ·çš„å‰ªæã€ŠEagleEye: Fast sub-net evaluation for efficient neural network pruningã€‹æœ€è¿‘ä¹Ÿè¡¨ç°å‡ºæ¯”è¾ƒå¥½çš„å‰ªææ•ˆæœã€‚å¾—åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹ä¹‹åï¼Œè¿›è¡Œå­æ¨¡å‹é‡‡æ ·è¿‡ç¨‹ã€‚ä¸€æ¬¡å­æ¨¡å‹é‡‡æ ·è¿‡ç¨‹ä¸ºï¼š\n1ï¼‰å¯¹è®­ç»ƒå¥½çš„åŸæ¨¡å‹ä¸­å¯ä¿®å‰ªçš„ç½‘ç»œç»“æ„ï¼ŒæŒ‰ç…§å‰ªæç›®æ ‡è¿›è¡Œé‡‡æ ·ï¼Œé‡‡æ ·è¿‡ç¨‹å¯ä»¥æ˜¯éšæœºçš„ï¼Œä¹Ÿå¯ä»¥æŒ‰ç…§ç½‘ç»œç»“æ„çš„é‡è¦æ€§æˆ–è€…é€šè¿‡KLæ•£åº¦è®¡ç®—è¿›è¡Œæ¦‚ç‡é‡‡æ ·ã€‚\n2ï¼‰å¯¹é‡‡æ ·åçš„ç½‘ç»œç»“æ„è¿›è¡Œå‰ªæï¼Œå¾—åˆ°é‡‡æ ·å­æ¨¡å‹ã€‚å­æ¨¡å‹é‡‡æ ·è¿‡ç¨‹é€šå¸¸è¿›è¡Œå¤šæ¬¡ï¼Œå¾—åˆ°å¤šä¸ªå­æ¨¡å‹ï¼ˆnâ‰¥1ï¼‰ã€‚è¿™äº›å­æ¨¡å‹æ˜¯åŸæ¨¡å‹çš„ä¸åŒç®€åŒ–ç‰ˆæœ¬ï¼Œå®ƒä»¬çš„ç½‘ç»œç»“æ„å’Œå‚æ•°æ•°é‡éƒ½æœ‰æ‰€å‡å°‘ã€‚\nåŸºäºæœç´¢çš„å‰ªææµç¨‹ åŸºäºæœç´¢çš„å‰ªæä¸»è¦ä¾é å¼ºåŒ–å­¦ä¹ ç­‰ä¸€ç³»åˆ—æ— ç›‘ç£å­¦ä¹ æˆ–è€…åŠç›‘ç£å­¦ä¹ ç®—æ³•ï¼Œä¹Ÿå¯ä»¥æ˜¯ç¥ç»ç½‘ç»œç»“æ„æœç´¢ç›¸å…³ç†è®ºã€‚\nç»™å®šå‰ªæç›®æ ‡ä¹‹åï¼ŒåŸºäºæœç´¢çš„å‰ªæåœ¨ç½‘ç»œç»“æ„ä¸­æœç´¢è¾ƒä¼˜çš„å­ç»“æ„ï¼Œè¿™ä¸ªæœç´¢è¿‡ç¨‹å¾€å¾€ä¼´éšç€ç½‘ç»œå‚æ•°çš„å­¦ä¹ è¿‡ç¨‹ï¼Œå› æ­¤ä¸€äº›åŸºäºæœç´¢çš„å‰ªæç®—æ³•åœ¨å‰ªæç»“æŸåä¸éœ€è¦å†è¿›è¡Œå¾®è°ƒã€‚\n","permalink":"https://codeofwhite.github.io/posts/llm/%E6%A8%A1%E5%9E%8B%E5%89%AA%E6%9E%9D-pruning/","summary":"\u003ch2 id=\"ä¸ºä»€ä¹ˆéœ€è¦å‰ªæ\"\u003eä¸ºä»€ä¹ˆéœ€è¦å‰ªæï¼Ÿ\u003c/h2\u003e\n\u003cp\u003eè¿‡å‚æ•°åŒ–ä¸»è¦æ˜¯æŒ‡åœ¨è®­ç»ƒé˜¶æ®µï¼Œåœ¨æ•°å­¦ä¸Šéœ€è¦è¿›è¡Œå¤§é‡çš„å¾®åˆ†æ±‚è§£ï¼Œå»æ•æŠ“æ•°æ®ä¸­çš„å¾®å°å˜åŒ–ä¿¡æ¯ï¼Œä¸€æ—¦å®Œæˆè¿­ä»£å¼çš„è®­ç»ƒä¹‹åï¼Œç½‘ç»œæ¨¡å‹æ¨ç†çš„æ—¶å€™å°±ä¸éœ€è¦è¿™ä¹ˆå¤šå‚æ•°ã€‚è€Œå‰ªæç®—æ³•æ­£æ˜¯åŸºäºè¿‡å‚æ•°åŒ–çš„ç†è®ºåŸºç¡€è€Œæå‡ºçš„ã€‚\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eæ ¸å¿ƒæ€æƒ³ï¼šå‡å°‘ç½‘ç»œæ¨¡å‹ä¸­å‚æ•°é‡å’Œè®¡ç®—é‡ï¼ŒåŒæ—¶å°½é‡ä¿è¯æ¨¡å‹çš„æ€§èƒ½ä¸å—å½±å“ã€‚\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"å‰ªæç®—æ³•åˆ†ç±»\"\u003eå‰ªæç®—æ³•åˆ†ç±»\u003c/h2\u003e\n\u003cp\u003e1ï¼‰Drop Outï¼šéšæœºçš„å°†ä¸€äº›ç¥ç»å…ƒçš„è¾“å‡ºç½®é›¶ï¼Œç§°ä¹‹ä¸ºç¥ç»å…ƒå‰ªæã€‚ã€è¿™ä¸ªä¸€çœ¼çœ‹åˆ°å°±æ„Ÿè§‰ä¼šæœ‰é—®é¢˜ã€‘\n2ï¼‰Drop Connectï¼šéšæœºå°†éƒ¨åˆ†ç¥ç»å…ƒé—´çš„è¿æ¥Connectç½®é›¶ï¼Œä½¿å¾—æƒé‡è¿æ¥çŸ©é˜µå˜å¾—ç¨€ç–ã€‚ã€è¿™ä¸ªè¿˜å¯ä»¥ã€‘\u003c/p\u003e\n\u003ch3 id=\"ç»“æ„åŒ–å‰ªæ-éç»“æ„åŒ–å‰ªæ\"\u003eç»“æ„åŒ–å‰ªæ éç»“æ„åŒ–å‰ªæ\u003c/h3\u003e\n\u003cp\u003e1)Â \u003cstrong\u003eç»†ç²’åº¦å‰ªæ(fine-grained)\u003c/strong\u003eï¼šå³å¯¹è¿æ¥æˆ–è€…ç¥ç»å…ƒè¿›è¡Œå‰ªæï¼Œæ˜¯ç²’åº¦æœ€å°çš„å‰ªæï¼Œä¸Šé¢Drop Outå’ŒDrop Connectéƒ½æ˜¯å±äºç»†ç²’åº¦å‰ªæã€‚\n2) \u003cstrong\u003eå‘é‡å‰ªæ(vector-level)\u003c/strong\u003eï¼šå®ƒç›¸å¯¹äºç»†ç²’åº¦å‰ªæç²’åº¦ç¨å¤§ï¼Œå±äºå¯¹å·ç§¯æ ¸å†…éƒ¨(intra-kernel) çš„å‰ªæã€‚\n3) \u003cstrong\u003eæ ¸å‰ªæ(kernel-level)\u003c/strong\u003eï¼šå³å»é™¤æŸä¸ªå·ç§¯æ ¸ï¼Œä¸¢å¼ƒå¯¹è¾“å…¥é€šé“ä¸­å¯¹åº”å·ç§¯æ ¸çš„è®¡ç®—ã€‚\n4) \u003cstrong\u003eæ»¤æ³¢å™¨å‰ªæ(Filter-level)\u003c/strong\u003eï¼šå¯¹æ•´ä¸ªå·ç§¯æ ¸ç»„è¿›è¡Œå‰ªæï¼Œ==æ¨ç†è¿‡ç¨‹ä¸­è¾“å‡ºç‰¹å¾é€šé“æ•°ä¼šæ”¹å˜==ã€‚\u003c/p\u003e\n\u003cp\u003eç»†ç²’åº¦å‰ªæã€å‘é‡å‰ªæã€æ ¸å‰ªæåœ¨å‚æ•°é‡ä¸æ¨¡å‹æ€§èƒ½ä¹‹é—´å–å¾—äº†ä¸€å®šçš„å¹³è¡¡ï¼Œä½†æ˜¯ç½‘ç»œæ¨¡å‹å•å±‚çš„ç¥ç»å…ƒä¹‹é—´çš„ç»„åˆç»“æ„å‘ç”Ÿäº†å˜åŒ–ï¼Œéœ€è¦ä¸“é—¨çš„ç®—æ³•æˆ–è€…ç¡¬ä»¶ç»“æ„æ¥æ”¯æŒç¨€ç–çš„è¿ç®—ï¼Œè¿™ç§å«åš\u003cstrong\u003eéç»“æ„åŒ–å‰ªæï¼ˆUnstructured Pruningï¼‰\u003c/strong\u003eã€‚\u003c/p\u003e\n\u003cp\u003eå…¶ä¸­ï¼Œéç»“æ„åŒ–å‰ªæèƒ½å¤Ÿå®ç°æ›´é«˜çš„å‹ç¼©ç‡ï¼ŒåŒæ—¶ä¿æŒè¾ƒé«˜çš„æ¨¡å‹æ€§èƒ½ï¼Œç„¶è€Œä¼šå¸¦æ¥ç½‘ç»œæ¨¡å‹ç¨€ç–åŒ–ï¼Œå…¶ç¨€ç–ç»“æ„å¯¹äºç¡¬ä»¶åŠ é€Ÿè®¡ç®—å¹¶ä¸å‹å¥½ï¼Œé™¤éåº•å±‚ç¡¬ä»¶å’Œè®¡ç®—åŠ é€Ÿåº“å¯¹ç¨€ç–è®¡ç®—æœ‰æ¯”è¾ƒå¥½çš„æ”¯æŒï¼Œå¦åˆ™å‰ªæåå¾ˆéš¾è·å¾—å®è´¨çš„æ€§èƒ½æå‡ã€‚\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eæ»¤æ³¢å™¨å‰ªæï¼ˆFilter-levelï¼‰\u003c/strong\u003e ä¸»è¦æ”¹å˜ç½‘ç»œä¸­çš„æ»¤æ³¢å™¨ç»„å’Œç‰¹å¾é€šé“æ•°ç›®ï¼Œæ‰€è·å¾—çš„æ¨¡å‹ä¸éœ€è¦ä¸“é—¨çš„ç®—æ³•å’Œç¡¬ä»¶å°±èƒ½å¤Ÿè¿è¡Œï¼Œè¢«ç§°ä¸º\u003cstrong\u003eç»“æ„åŒ–å‰ªæï¼ˆStructured Pruningï¼‰\u003c/strong\u003eã€‚ç»“æ„åŒ–å‰ªæåˆå¯è¿›ä¸€æ­¥ç»†åˆ†ï¼šå¯ä»¥æ˜¯channel-wiseï¼Œä¹Ÿå¯ä»¥æ˜¯filter-wiseï¼Œè¿˜å¯ä»¥æ˜¯åœ¨shape-wiseã€‚\u003c/p\u003e\n\u003cp\u003eç»“æ„åŒ–å‰ªæä¸éç»“æ„åŒ–å‰ªææ°æ°ç›¸åï¼Œå¯ä»¥æ–¹ä¾¿æ”¹å˜ç½‘ç»œæ¨¡å‹çš„ç»“æ„ç‰¹å¾ï¼Œä»è€Œè¾¾åˆ°å‹ç¼©æ¨¡å‹çš„æ•ˆæœï¼Œä¾‹å¦‚çŸ¥è¯†è’¸é¦ä¸­çš„studentç½‘ç»œæ¨¡å‹ã€NASæœç´¢æˆ–è€…å¦‚VGG19å’ŒVGG16è¿™ç§è£å‰ªæ¨¡å‹ï¼Œä¹Ÿå¯ä»¥çœ‹åšå˜ç›¸çš„ç»“æ„åŒ–å‰ªæè¡Œä¸ºã€‚\u003c/p\u003e\n\u003ch2 id=\"å‰ªæç®—æ³•æµç¨‹\"\u003eå‰ªæç®—æ³•æµç¨‹\u003c/h2\u003e\n\u003cp\u003eè™½ç„¶å‰ªæç®—æ³•çš„åˆ†ç±»çœ‹ä¸Šå»å¾ˆå¤šï¼Œä½†æ˜¯æ ¸å¿ƒæ€æƒ³è¿˜æ˜¯å¯¹ç¥ç»ç½‘ç»œæ¨¡å‹è¿›è¡Œå‰ªæï¼Œç›®å‰å‰ªæç®—æ³•çš„æ€»ä½“æµç¨‹å¤§åŒå°å¼‚ï¼Œå¯ä»¥å½’ç»“ä¸ºä¸‰ç§ï¼š\u003cstrong\u003eæ ‡å‡†å‰ªæ\u003c/strong\u003eã€\u003cstrong\u003eåŸºäºå­æ¨¡å‹é‡‡æ ·çš„å‰ªæ\u003c/strong\u003eã€ä»¥åŠ\u003cstrong\u003eåŸºäºæœç´¢çš„å‰ªæ\u003c/strong\u003eï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚\u003c/p\u003e\n\u003ch3 id=\"æ ‡å‡†å‰ªæç®—æ³•æµç¨‹\"\u003eæ ‡å‡†å‰ªæç®—æ³•æµç¨‹\u003c/h3\u003e\n\u003cp\u003eæ ‡å‡†å‰ªææ˜¯ç›®å‰æœ€æµè¡Œçš„å‰ªææµç¨‹ï¼Œåœ¨Tensorflowã€Pytrochéƒ½æœ‰æ ‡å‡†çš„æ¥å£ã€‚ä¸»è¦åŒ…å«ä¸‰ä¸ªéƒ¨åˆ†ï¼šè®­ç»ƒã€å‰ªæã€ä»¥åŠå¾®è°ƒã€‚\u003c/p\u003e\n\u003cp\u003e1ï¼‰\u003cstrong\u003eè®­ç»ƒ\u003c/strong\u003eï¼šé¦–å…ˆæ˜¯å¯¹ç½‘ç»œæ¨¡å‹è¿›è¡Œè®­ç»ƒã€‚åœ¨å‰ªææµç¨‹ä¸­ï¼Œè®­ç»ƒéƒ¨åˆ†ä¸»è¦æŒ‡é¢„è®­ç»ƒï¼Œè®­ç»ƒçš„ç›®çš„æ˜¯ä¸ºå‰ªæç®—æ³•è·å¾—åœ¨ç‰¹å®šåŸºç¡€SOTAä»»åŠ¡ä¸Šè®­ç»ƒå¥½çš„åŸå§‹æ¨¡å‹ã€‚\n2ï¼‰\u003cstrong\u003eå‰ªæ\u003c/strong\u003eï¼šåœ¨è¿™é‡Œé¢å¯ä»¥è¿›è¡Œå¦‚ç»†ç²’åº¦å‰ªæã€å‘é‡å‰ªæã€æ ¸å‰ªæã€æ»¤æ³¢å™¨å‰ªæç­‰å„ç§ä¸åŒçš„å‰ªæç®—æ³•ã€‚å…¶ä¸­å¾ˆé‡è¦çš„å°±ä¸€ç‚¹ï¼Œå°±æ˜¯åœ¨å‰ªæä¹‹åï¼Œ==å¯¹ç½‘ç»œæ¨¡å‹ç»“æ„è¿›è¡Œè¯„ä¼°==ã€‚ç¡®å®šä¸€ä¸ªéœ€è¦å‰ªæçš„å±‚ï¼Œè®¾å®šä¸€ä¸ªè£å‰ªé˜ˆå€¼æˆ–è€…æ¯”ä¾‹ã€‚å®ç°ä¸Šï¼Œé€šè¿‡ä¿®æ”¹ä»£ç åŠ å…¥ä¸€ä¸ªä¸å‚æ•°çŸ©é˜µå°ºå¯¸ä¸€è‡´çš„==MaskçŸ©é˜µ==ã€‚MaskçŸ©é˜µä¸­åªæœ‰0å’Œ1ï¼Œå®é™…ä¸Šæ˜¯ç”¨äºå¾®è°ƒç½‘ç»œã€‚\n3ï¼‰ \u003cstrong\u003eå¾®è°ƒ\u003c/strong\u003eï¼šå¾®è°ƒæ˜¯æ¢å¤è¢«å‰ªææ“ä½œå½±å“çš„æ¨¡å‹è¡¨è¾¾èƒ½åŠ›çš„å¿…è¦æ­¥éª¤ã€‚ç»“æ„åŒ–æ¨¡å‹å‰ªæä¼šå¯¹åŸå§‹æ¨¡å‹ç»“æ„è¿›è¡Œè°ƒæ•´ï¼Œå› æ­¤å‰ªæåçš„æ¨¡å‹å‚æ•°è™½ç„¶ä¿ç•™äº†åŸå§‹çš„æ¨¡å‹å‚æ•°ï¼Œä½†æ˜¯==ç”±äºæ¨¡å‹ç»“æ„çš„æ”¹å˜ï¼Œå‰ªæåæ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›ä¼šå—åˆ°ä¸€å®šç¨‹åº¦çš„å½±å“==ã€‚å®ç°ä¸Šï¼Œå¾®è°ƒç½‘ç»œæ¨¡å‹ï¼Œå‚æ•°åœ¨è®¡ç®—çš„æ—¶å€™å…ˆä¹˜ä»¥è¯¥Maskï¼ŒMaskä¸º1çš„å‚æ•°å€¼å°†ç»§ç»­è®­ç»ƒé€šè¿‡BPè°ƒæ•´æ¢¯åº¦ï¼Œè€ŒMaskä¸º0çš„éƒ¨åˆ†å› ä¸ºè¾“å‡ºå§‹ç»ˆä¸º0åˆ™ä¸å¯¹åç»­éƒ¨åˆ†äº§ç”Ÿå½±å“ã€‚\n4ï¼‰\u003cstrong\u003eå†å‰ªæ\u003c/strong\u003eï¼šå†å‰ªæè¿‡ç¨‹å°†å¾®è°ƒä¹‹åçš„ç½‘ç»œæ¨¡å‹å†é€åˆ°å‰ªææ¨¡å—ä¸­ï¼Œå†æ¬¡è¿›è¡Œæ¨¡å‹ç»“æ„è¯„ä¼°å’Œæ‰§è¡Œå‰ªæç®—æ³•ã€‚ç›®çš„æ˜¯ä½¿å¾—æ¯æ¬¡å‰ªæéƒ½åœ¨æ€§èƒ½æ›´ä¼˜çš„æ¨¡å‹ä¸Šé¢è¿›è¡Œï¼Œä¸æ–­è¿­ä»£å¼åœ°è¿›è¡Œä¼˜åŒ–å‰ªææ¨¡å‹ï¼Œç›´åˆ°æ¨¡å‹èƒ½å¤Ÿæ»¡è¶³å‰ªæç›®æ ‡éœ€æ±‚ã€‚\u003c/p\u003e\n\u003cp\u003eæœ€åè¾“å‡ºæ¨¡å‹å‚æ•°å‚¨å­˜çš„æ—¶å€™ï¼Œå› ä¸ºæœ‰==å¤§é‡çš„ç¨€ç–==ï¼Œæ‰€ä»¥å¯ä»¥é‡æ–°å®šä¹‰å‚¨å­˜çš„æ•°æ®ç»“æ„ï¼Œ ==ä»…å‚¨å­˜éé›¶å€¼ä»¥åŠå…¶çŸ©é˜µä½ç½®==ã€‚é‡æ–°è¯»å–æ¨¡å‹å‚æ•°çš„æ—¶å€™ï¼Œå°±å¯ä»¥è¿˜åŸçŸ©é˜µã€‚\u003c/p\u003e\n\u003ch3 id=\"åŸºäºå­æ¨¡å‹é‡‡æ ·æµç¨‹\"\u003eåŸºäºå­æ¨¡å‹é‡‡æ ·æµç¨‹\u003c/h3\u003e\n\u003cp\u003eé™¤æ ‡å‡†å‰ªæä¹‹å¤–ï¼ŒåŸºäºå­æ¨¡å‹é‡‡æ ·çš„å‰ªæã€ŠEagleEye: Fast sub-net evaluation for efficient neural network pruningã€‹æœ€è¿‘ä¹Ÿè¡¨ç°å‡ºæ¯”è¾ƒå¥½çš„å‰ªææ•ˆæœã€‚å¾—åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹ä¹‹åï¼Œè¿›è¡Œå­æ¨¡å‹é‡‡æ ·è¿‡ç¨‹ã€‚ä¸€æ¬¡å­æ¨¡å‹é‡‡æ ·è¿‡ç¨‹ä¸ºï¼š\u003c/p\u003e\n\u003cp\u003e1ï¼‰å¯¹è®­ç»ƒå¥½çš„åŸæ¨¡å‹ä¸­å¯ä¿®å‰ªçš„ç½‘ç»œç»“æ„ï¼ŒæŒ‰ç…§å‰ªæç›®æ ‡è¿›è¡Œé‡‡æ ·ï¼Œé‡‡æ ·è¿‡ç¨‹å¯ä»¥æ˜¯éšæœºçš„ï¼Œä¹Ÿå¯ä»¥æŒ‰ç…§ç½‘ç»œç»“æ„çš„é‡è¦æ€§æˆ–è€…é€šè¿‡KLæ•£åº¦è®¡ç®—è¿›è¡Œæ¦‚ç‡é‡‡æ ·ã€‚\u003c/p\u003e\n\u003cp\u003e2ï¼‰å¯¹é‡‡æ ·åçš„ç½‘ç»œç»“æ„è¿›è¡Œå‰ªæï¼Œå¾—åˆ°é‡‡æ ·å­æ¨¡å‹ã€‚å­æ¨¡å‹é‡‡æ ·è¿‡ç¨‹é€šå¸¸è¿›è¡Œå¤šæ¬¡ï¼Œå¾—åˆ°å¤šä¸ªå­æ¨¡å‹ï¼ˆnâ‰¥1ï¼‰ã€‚è¿™äº›å­æ¨¡å‹æ˜¯åŸæ¨¡å‹çš„ä¸åŒç®€åŒ–ç‰ˆæœ¬ï¼Œå®ƒä»¬çš„ç½‘ç»œç»“æ„å’Œå‚æ•°æ•°é‡éƒ½æœ‰æ‰€å‡å°‘ã€‚\u003c/p\u003e\n\u003ch3 id=\"åŸºäºæœç´¢çš„å‰ªææµç¨‹\"\u003eåŸºäºæœç´¢çš„å‰ªææµç¨‹\u003c/h3\u003e\n\u003cp\u003eåŸºäºæœç´¢çš„å‰ªæä¸»è¦ä¾é å¼ºåŒ–å­¦ä¹ ç­‰ä¸€ç³»åˆ—æ— ç›‘ç£å­¦ä¹ æˆ–è€…åŠç›‘ç£å­¦ä¹ ç®—æ³•ï¼Œä¹Ÿå¯ä»¥æ˜¯ç¥ç»ç½‘ç»œç»“æ„æœç´¢ç›¸å…³ç†è®ºã€‚\u003c/p\u003e\n\u003cp\u003eç»™å®šå‰ªæç›®æ ‡ä¹‹åï¼ŒåŸºäºæœç´¢çš„å‰ªæåœ¨ç½‘ç»œç»“æ„ä¸­æœç´¢è¾ƒä¼˜çš„å­ç»“æ„ï¼Œè¿™ä¸ªæœç´¢è¿‡ç¨‹å¾€å¾€ä¼´éšç€ç½‘ç»œå‚æ•°çš„å­¦ä¹ è¿‡ç¨‹ï¼Œå› æ­¤ä¸€äº›åŸºäºæœç´¢çš„å‰ªæç®—æ³•åœ¨å‰ªæç»“æŸåä¸éœ€è¦å†è¿›è¡Œå¾®è°ƒã€‚\u003c/p\u003e","title":"æ¨¡å‹å‰ªæ Pruning"}]